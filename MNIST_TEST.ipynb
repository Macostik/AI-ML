{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYErysH3alxDEFnSuF7G4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Macostik/MNIST_TEST/blob/master/MNIST_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"data/mnist_data_model.pth\")"
      ],
      "metadata": {
        "id": "PHaAP1UUUr7A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUIcX0TuLbUP",
        "outputId": "fef260bd-6a62-4ac3-c19a-e86c36e2383a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7b15ae4d6110>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7b15ae4d6050>\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (liner_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n",
            "epoch 1 \n",
            " --------------------------\n",
            "loss: 2.313947 [    0 / 60000]\n",
            "loss: 1.464764 [ 6400 / 60000]\n",
            "loss: 1.295068 [12800 / 60000]\n",
            "loss: 1.359335 [19200 / 60000]\n",
            "loss: 1.251369 [25600 / 60000]\n",
            "loss: 1.346058 [32000 / 60000]\n",
            "loss: 1.295514 [38400 / 60000]\n",
            "loss: 1.415670 [44800 / 60000]\n",
            "loss: 1.332393 [51200 / 60000]\n",
            "loss: 1.386377 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 53.0% Avg loss 0.020855 \n",
            "\n",
            "epoch 2 \n",
            " --------------------------\n",
            "loss: 1.237442 [    0 / 60000]\n",
            "loss: 1.216736 [ 6400 / 60000]\n",
            "loss: 1.214084 [12800 / 60000]\n",
            "loss: 1.236464 [19200 / 60000]\n",
            "loss: 1.129829 [25600 / 60000]\n",
            "loss: 1.318842 [32000 / 60000]\n",
            "loss: 1.265502 [38400 / 60000]\n",
            "loss: 1.402036 [44800 / 60000]\n",
            "loss: 1.256884 [51200 / 60000]\n",
            "loss: 1.366611 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 54.4% Avg loss 0.020454 \n",
            "\n",
            "epoch 3 \n",
            " --------------------------\n",
            "loss: 1.203257 [    0 / 60000]\n",
            "loss: 1.192731 [ 6400 / 60000]\n",
            "loss: 1.178542 [12800 / 60000]\n",
            "loss: 1.207788 [19200 / 60000]\n",
            "loss: 1.094072 [25600 / 60000]\n",
            "loss: 1.314242 [32000 / 60000]\n",
            "loss: 1.250115 [38400 / 60000]\n",
            "loss: 1.388461 [44800 / 60000]\n",
            "loss: 1.069650 [51200 / 60000]\n",
            "loss: 1.297080 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 55.5% Avg loss 0.018448 \n",
            "\n",
            "epoch 4 \n",
            " --------------------------\n",
            "loss: 1.027244 [    0 / 60000]\n",
            "loss: 0.900087 [ 6400 / 60000]\n",
            "loss: 0.911661 [12800 / 60000]\n",
            "loss: 1.097985 [19200 / 60000]\n",
            "loss: 0.866590 [25600 / 60000]\n",
            "loss: 1.153492 [32000 / 60000]\n",
            "loss: 1.001850 [38400 / 60000]\n",
            "loss: 1.164183 [44800 / 60000]\n",
            "loss: 0.968485 [51200 / 60000]\n",
            "loss: 1.099166 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 61.6% Avg loss 0.015977 \n",
            "\n",
            "epoch 5 \n",
            " --------------------------\n",
            "loss: 0.753276 [    0 / 60000]\n",
            "loss: 0.733479 [ 6400 / 60000]\n",
            "loss: 0.853077 [12800 / 60000]\n",
            "loss: 1.024430 [19200 / 60000]\n",
            "loss: 0.753681 [25600 / 60000]\n",
            "loss: 0.942240 [32000 / 60000]\n",
            "loss: 0.825548 [38400 / 60000]\n",
            "loss: 0.855276 [44800 / 60000]\n",
            "loss: 0.899821 [51200 / 60000]\n",
            "loss: 0.705027 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 71.6% Avg loss 0.011527 \n",
            "\n",
            "epoch 6 \n",
            " --------------------------\n",
            "loss: 0.452850 [    0 / 60000]\n",
            "loss: 0.503948 [ 6400 / 60000]\n",
            "loss: 0.482873 [12800 / 60000]\n",
            "loss: 0.670607 [19200 / 60000]\n",
            "loss: 0.549902 [25600 / 60000]\n",
            "loss: 0.452732 [32000 / 60000]\n",
            "loss: 0.388195 [38400 / 60000]\n",
            "loss: 0.476379 [44800 / 60000]\n",
            "loss: 0.457044 [51200 / 60000]\n",
            "loss: 0.403909 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 83.0% Avg loss 0.007117 \n",
            "\n",
            "epoch 7 \n",
            " --------------------------\n",
            "loss: 0.290308 [    0 / 60000]\n",
            "loss: 0.339839 [ 6400 / 60000]\n",
            "loss: 0.251223 [12800 / 60000]\n",
            "loss: 0.335058 [19200 / 60000]\n",
            "loss: 0.316898 [25600 / 60000]\n",
            "loss: 0.392517 [32000 / 60000]\n",
            "loss: 0.308024 [38400 / 60000]\n",
            "loss: 0.435861 [44800 / 60000]\n",
            "loss: 0.417924 [51200 / 60000]\n",
            "loss: 0.381569 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 84.5% Avg loss 0.006569 \n",
            "\n",
            "epoch 8 \n",
            " --------------------------\n",
            "loss: 0.244176 [    0 / 60000]\n",
            "loss: 0.315397 [ 6400 / 60000]\n",
            "loss: 0.222911 [12800 / 60000]\n",
            "loss: 0.304790 [19200 / 60000]\n",
            "loss: 0.317004 [25600 / 60000]\n",
            "loss: 0.369211 [32000 / 60000]\n",
            "loss: 0.290668 [38400 / 60000]\n",
            "loss: 0.391092 [44800 / 60000]\n",
            "loss: 0.376984 [51200 / 60000]\n",
            "loss: 0.356883 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 85.4% Avg loss 0.006301 \n",
            "\n",
            "epoch 9 \n",
            " --------------------------\n",
            "loss: 0.227063 [    0 / 60000]\n",
            "loss: 0.296919 [ 6400 / 60000]\n",
            "loss: 0.196110 [12800 / 60000]\n",
            "loss: 0.283937 [19200 / 60000]\n",
            "loss: 0.311270 [25600 / 60000]\n",
            "loss: 0.361044 [32000 / 60000]\n",
            "loss: 0.265099 [38400 / 60000]\n",
            "loss: 0.363678 [44800 / 60000]\n",
            "loss: 0.352591 [51200 / 60000]\n",
            "loss: 0.341815 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 86.3% Avg loss 0.005919 \n",
            "\n",
            "epoch 10 \n",
            " --------------------------\n",
            "loss: 0.195458 [    0 / 60000]\n",
            "loss: 0.288097 [ 6400 / 60000]\n",
            "loss: 0.184400 [12800 / 60000]\n",
            "loss: 0.268911 [19200 / 60000]\n",
            "loss: 0.310973 [25600 / 60000]\n",
            "loss: 0.346589 [32000 / 60000]\n",
            "loss: 0.250308 [38400 / 60000]\n",
            "loss: 0.351587 [44800 / 60000]\n",
            "loss: 0.329280 [51200 / 60000]\n",
            "loss: 0.317761 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 86.6% Avg loss 0.005783 \n",
            "\n",
            "epoch 11 \n",
            " --------------------------\n",
            "loss: 0.188438 [    0 / 60000]\n",
            "loss: 0.270977 [ 6400 / 60000]\n",
            "loss: 0.169662 [12800 / 60000]\n",
            "loss: 0.268695 [19200 / 60000]\n",
            "loss: 0.310897 [25600 / 60000]\n",
            "loss: 0.336889 [32000 / 60000]\n",
            "loss: 0.225632 [38400 / 60000]\n",
            "loss: 0.330360 [44800 / 60000]\n",
            "loss: 0.307216 [51200 / 60000]\n",
            "loss: 0.333411 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.0% Avg loss 0.005619 \n",
            "\n",
            "epoch 12 \n",
            " --------------------------\n",
            "loss: 0.183097 [    0 / 60000]\n",
            "loss: 0.267843 [ 6400 / 60000]\n",
            "loss: 0.164849 [12800 / 60000]\n",
            "loss: 0.259879 [19200 / 60000]\n",
            "loss: 0.307432 [25600 / 60000]\n",
            "loss: 0.326302 [32000 / 60000]\n",
            "loss: 0.212133 [38400 / 60000]\n",
            "loss: 0.304473 [44800 / 60000]\n",
            "loss: 0.306920 [51200 / 60000]\n",
            "loss: 0.319346 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 86.9% Avg loss 0.005591 \n",
            "\n",
            "epoch 13 \n",
            " --------------------------\n",
            "loss: 0.179735 [    0 / 60000]\n",
            "loss: 0.256447 [ 6400 / 60000]\n",
            "loss: 0.158198 [12800 / 60000]\n",
            "loss: 0.236412 [19200 / 60000]\n",
            "loss: 0.305256 [25600 / 60000]\n",
            "loss: 0.314951 [32000 / 60000]\n",
            "loss: 0.204824 [38400 / 60000]\n",
            "loss: 0.289392 [44800 / 60000]\n",
            "loss: 0.290356 [51200 / 60000]\n",
            "loss: 0.297437 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.1% Avg loss 0.005529 \n",
            "\n",
            "epoch 14 \n",
            " --------------------------\n",
            "loss: 0.184124 [    0 / 60000]\n",
            "loss: 0.238800 [ 6400 / 60000]\n",
            "loss: 0.150280 [12800 / 60000]\n",
            "loss: 0.228676 [19200 / 60000]\n",
            "loss: 0.289308 [25600 / 60000]\n",
            "loss: 0.297093 [32000 / 60000]\n",
            "loss: 0.195877 [38400 / 60000]\n",
            "loss: 0.268663 [44800 / 60000]\n",
            "loss: 0.297451 [51200 / 60000]\n",
            "loss: 0.294304 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.5% Avg loss 0.005404 \n",
            "\n",
            "epoch 15 \n",
            " --------------------------\n",
            "loss: 0.174749 [    0 / 60000]\n",
            "loss: 0.226609 [ 6400 / 60000]\n",
            "loss: 0.143534 [12800 / 60000]\n",
            "loss: 0.235628 [19200 / 60000]\n",
            "loss: 0.278373 [25600 / 60000]\n",
            "loss: 0.293598 [32000 / 60000]\n",
            "loss: 0.178637 [38400 / 60000]\n",
            "loss: 0.258836 [44800 / 60000]\n",
            "loss: 0.269062 [51200 / 60000]\n",
            "loss: 0.278809 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.9% Avg loss 0.005352 \n",
            "\n",
            "epoch 16 \n",
            " --------------------------\n",
            "loss: 0.165252 [    0 / 60000]\n",
            "loss: 0.219869 [ 6400 / 60000]\n",
            "loss: 0.148901 [12800 / 60000]\n",
            "loss: 0.206492 [19200 / 60000]\n",
            "loss: 0.276922 [25600 / 60000]\n",
            "loss: 0.288612 [32000 / 60000]\n",
            "loss: 0.180367 [38400 / 60000]\n",
            "loss: 0.245080 [44800 / 60000]\n",
            "loss: 0.277723 [51200 / 60000]\n",
            "loss: 0.268896 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.8% Avg loss 0.005361 \n",
            "\n",
            "epoch 17 \n",
            " --------------------------\n",
            "loss: 0.153220 [    0 / 60000]\n",
            "loss: 0.205514 [ 6400 / 60000]\n",
            "loss: 0.138077 [12800 / 60000]\n",
            "loss: 0.199859 [19200 / 60000]\n",
            "loss: 0.273496 [25600 / 60000]\n",
            "loss: 0.286002 [32000 / 60000]\n",
            "loss: 0.171272 [38400 / 60000]\n",
            "loss: 0.239328 [44800 / 60000]\n",
            "loss: 0.296948 [51200 / 60000]\n",
            "loss: 0.273573 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.0% Avg loss 0.005371 \n",
            "\n",
            "epoch 18 \n",
            " --------------------------\n",
            "loss: 0.149679 [    0 / 60000]\n",
            "loss: 0.199269 [ 6400 / 60000]\n",
            "loss: 0.151665 [12800 / 60000]\n",
            "loss: 0.187269 [19200 / 60000]\n",
            "loss: 0.260413 [25600 / 60000]\n",
            "loss: 0.276050 [32000 / 60000]\n",
            "loss: 0.182696 [38400 / 60000]\n",
            "loss: 0.229508 [44800 / 60000]\n",
            "loss: 0.279721 [51200 / 60000]\n",
            "loss: 0.262779 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.9% Avg loss 0.005388 \n",
            "\n",
            "epoch 19 \n",
            " --------------------------\n",
            "loss: 0.153017 [    0 / 60000]\n",
            "loss: 0.187949 [ 6400 / 60000]\n",
            "loss: 0.143367 [12800 / 60000]\n",
            "loss: 0.198676 [19200 / 60000]\n",
            "loss: 0.257197 [25600 / 60000]\n",
            "loss: 0.277413 [32000 / 60000]\n",
            "loss: 0.157031 [38400 / 60000]\n",
            "loss: 0.225846 [44800 / 60000]\n",
            "loss: 0.253969 [51200 / 60000]\n",
            "loss: 0.255362 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.0% Avg loss 0.005387 \n",
            "\n",
            "epoch 20 \n",
            " --------------------------\n",
            "loss: 0.135939 [    0 / 60000]\n",
            "loss: 0.186321 [ 6400 / 60000]\n",
            "loss: 0.138790 [12800 / 60000]\n",
            "loss: 0.155531 [19200 / 60000]\n",
            "loss: 0.240327 [25600 / 60000]\n",
            "loss: 0.274648 [32000 / 60000]\n",
            "loss: 0.157316 [38400 / 60000]\n",
            "loss: 0.218825 [44800 / 60000]\n",
            "loss: 0.245744 [51200 / 60000]\n",
            "loss: 0.234167 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.1% Avg loss 0.005409 \n",
            "\n",
            "epoch 21 \n",
            " --------------------------\n",
            "loss: 0.133361 [    0 / 60000]\n",
            "loss: 0.192291 [ 6400 / 60000]\n",
            "loss: 0.136906 [12800 / 60000]\n",
            "loss: 0.149158 [19200 / 60000]\n",
            "loss: 0.226924 [25600 / 60000]\n",
            "loss: 0.265446 [32000 / 60000]\n",
            "loss: 0.145202 [38400 / 60000]\n",
            "loss: 0.194267 [44800 / 60000]\n",
            "loss: 0.229363 [51200 / 60000]\n",
            "loss: 0.223599 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.2% Avg loss 0.005471 \n",
            "\n",
            "epoch 22 \n",
            " --------------------------\n",
            "loss: 0.134950 [    0 / 60000]\n",
            "loss: 0.173882 [ 6400 / 60000]\n",
            "loss: 0.136224 [12800 / 60000]\n",
            "loss: 0.156325 [19200 / 60000]\n",
            "loss: 0.221301 [25600 / 60000]\n",
            "loss: 0.237439 [32000 / 60000]\n",
            "loss: 0.133767 [38400 / 60000]\n",
            "loss: 0.200356 [44800 / 60000]\n",
            "loss: 0.231053 [51200 / 60000]\n",
            "loss: 0.221872 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.005550 \n",
            "\n",
            "epoch 23 \n",
            " --------------------------\n",
            "loss: 0.138494 [    0 / 60000]\n",
            "loss: 0.170753 [ 6400 / 60000]\n",
            "loss: 0.125710 [12800 / 60000]\n",
            "loss: 0.143156 [19200 / 60000]\n",
            "loss: 0.222402 [25600 / 60000]\n",
            "loss: 0.244753 [32000 / 60000]\n",
            "loss: 0.128732 [38400 / 60000]\n",
            "loss: 0.181489 [44800 / 60000]\n",
            "loss: 0.216990 [51200 / 60000]\n",
            "loss: 0.203660 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.4% Avg loss 0.005502 \n",
            "\n",
            "epoch 24 \n",
            " --------------------------\n",
            "loss: 0.141123 [    0 / 60000]\n",
            "loss: 0.147182 [ 6400 / 60000]\n",
            "loss: 0.115805 [12800 / 60000]\n",
            "loss: 0.132685 [19200 / 60000]\n",
            "loss: 0.203532 [25600 / 60000]\n",
            "loss: 0.231461 [32000 / 60000]\n",
            "loss: 0.113595 [38400 / 60000]\n",
            "loss: 0.175541 [44800 / 60000]\n",
            "loss: 0.220020 [51200 / 60000]\n",
            "loss: 0.187355 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.0% Avg loss 0.005678 \n",
            "\n",
            "epoch 25 \n",
            " --------------------------\n",
            "loss: 0.133977 [    0 / 60000]\n",
            "loss: 0.159155 [ 6400 / 60000]\n",
            "loss: 0.107678 [12800 / 60000]\n",
            "loss: 0.132972 [19200 / 60000]\n",
            "loss: 0.206766 [25600 / 60000]\n",
            "loss: 0.212625 [32000 / 60000]\n",
            "loss: 0.115741 [38400 / 60000]\n",
            "loss: 0.167528 [44800 / 60000]\n",
            "loss: 0.204969 [51200 / 60000]\n",
            "loss: 0.174114 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.005625 \n",
            "\n",
            "epoch 26 \n",
            " --------------------------\n",
            "loss: 0.119078 [    0 / 60000]\n",
            "loss: 0.132961 [ 6400 / 60000]\n",
            "loss: 0.094707 [12800 / 60000]\n",
            "loss: 0.121356 [19200 / 60000]\n",
            "loss: 0.199015 [25600 / 60000]\n",
            "loss: 0.218984 [32000 / 60000]\n",
            "loss: 0.110986 [38400 / 60000]\n",
            "loss: 0.183404 [44800 / 60000]\n",
            "loss: 0.206025 [51200 / 60000]\n",
            "loss: 0.156347 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.005641 \n",
            "\n",
            "epoch 27 \n",
            " --------------------------\n",
            "loss: 0.125584 [    0 / 60000]\n",
            "loss: 0.134103 [ 6400 / 60000]\n",
            "loss: 0.104320 [12800 / 60000]\n",
            "loss: 0.132420 [19200 / 60000]\n",
            "loss: 0.176605 [25600 / 60000]\n",
            "loss: 0.204415 [32000 / 60000]\n",
            "loss: 0.106721 [38400 / 60000]\n",
            "loss: 0.162058 [44800 / 60000]\n",
            "loss: 0.167757 [51200 / 60000]\n",
            "loss: 0.158148 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.005709 \n",
            "\n",
            "epoch 28 \n",
            " --------------------------\n",
            "loss: 0.111119 [    0 / 60000]\n",
            "loss: 0.143674 [ 6400 / 60000]\n",
            "loss: 0.085268 [12800 / 60000]\n",
            "loss: 0.121894 [19200 / 60000]\n",
            "loss: 0.185354 [25600 / 60000]\n",
            "loss: 0.204889 [32000 / 60000]\n",
            "loss: 0.099415 [38400 / 60000]\n",
            "loss: 0.164495 [44800 / 60000]\n",
            "loss: 0.199314 [51200 / 60000]\n",
            "loss: 0.157122 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.2% Avg loss 0.005984 \n",
            "\n",
            "epoch 29 \n",
            " --------------------------\n",
            "loss: 0.129571 [    0 / 60000]\n",
            "loss: 0.135206 [ 6400 / 60000]\n",
            "loss: 0.083564 [12800 / 60000]\n",
            "loss: 0.119018 [19200 / 60000]\n",
            "loss: 0.182630 [25600 / 60000]\n",
            "loss: 0.214225 [32000 / 60000]\n",
            "loss: 0.096003 [38400 / 60000]\n",
            "loss: 0.163631 [44800 / 60000]\n",
            "loss: 0.183654 [51200 / 60000]\n",
            "loss: 0.151295 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.005849 \n",
            "\n",
            "epoch 30 \n",
            " --------------------------\n",
            "loss: 0.138349 [    0 / 60000]\n",
            "loss: 0.114252 [ 6400 / 60000]\n",
            "loss: 0.077521 [12800 / 60000]\n",
            "loss: 0.097118 [19200 / 60000]\n",
            "loss: 0.144629 [25600 / 60000]\n",
            "loss: 0.196537 [32000 / 60000]\n",
            "loss: 0.101433 [38400 / 60000]\n",
            "loss: 0.153909 [44800 / 60000]\n",
            "loss: 0.161764 [51200 / 60000]\n",
            "loss: 0.126306 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.1% Avg loss 0.006082 \n",
            "\n",
            "epoch 31 \n",
            " --------------------------\n",
            "loss: 0.109653 [    0 / 60000]\n",
            "loss: 0.109204 [ 6400 / 60000]\n",
            "loss: 0.076270 [12800 / 60000]\n",
            "loss: 0.088256 [19200 / 60000]\n",
            "loss: 0.162434 [25600 / 60000]\n",
            "loss: 0.182653 [32000 / 60000]\n",
            "loss: 0.096786 [38400 / 60000]\n",
            "loss: 0.137304 [44800 / 60000]\n",
            "loss: 0.189924 [51200 / 60000]\n",
            "loss: 0.138103 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.006062 \n",
            "\n",
            "epoch 32 \n",
            " --------------------------\n",
            "loss: 0.107492 [    0 / 60000]\n",
            "loss: 0.098752 [ 6400 / 60000]\n",
            "loss: 0.061370 [12800 / 60000]\n",
            "loss: 0.070673 [19200 / 60000]\n",
            "loss: 0.167821 [25600 / 60000]\n",
            "loss: 0.188325 [32000 / 60000]\n",
            "loss: 0.097536 [38400 / 60000]\n",
            "loss: 0.126078 [44800 / 60000]\n",
            "loss: 0.125341 [51200 / 60000]\n",
            "loss: 0.126032 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.8% Avg loss 0.006375 \n",
            "\n",
            "epoch 33 \n",
            " --------------------------\n",
            "loss: 0.123383 [    0 / 60000]\n",
            "loss: 0.096731 [ 6400 / 60000]\n",
            "loss: 0.069924 [12800 / 60000]\n",
            "loss: 0.072632 [19200 / 60000]\n",
            "loss: 0.141164 [25600 / 60000]\n",
            "loss: 0.181276 [32000 / 60000]\n",
            "loss: 0.074864 [38400 / 60000]\n",
            "loss: 0.139035 [44800 / 60000]\n",
            "loss: 0.137110 [51200 / 60000]\n",
            "loss: 0.114276 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.9% Avg loss 0.006443 \n",
            "\n",
            "epoch 34 \n",
            " --------------------------\n",
            "loss: 0.136452 [    0 / 60000]\n",
            "loss: 0.085740 [ 6400 / 60000]\n",
            "loss: 0.077505 [12800 / 60000]\n",
            "loss: 0.059995 [19200 / 60000]\n",
            "loss: 0.116378 [25600 / 60000]\n",
            "loss: 0.183021 [32000 / 60000]\n",
            "loss: 0.069213 [38400 / 60000]\n",
            "loss: 0.103131 [44800 / 60000]\n",
            "loss: 0.141925 [51200 / 60000]\n",
            "loss: 0.110205 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.9% Avg loss 0.006569 \n",
            "\n",
            "epoch 35 \n",
            " --------------------------\n",
            "loss: 0.094057 [    0 / 60000]\n",
            "loss: 0.094623 [ 6400 / 60000]\n",
            "loss: 0.079565 [12800 / 60000]\n",
            "loss: 0.062355 [19200 / 60000]\n",
            "loss: 0.117216 [25600 / 60000]\n",
            "loss: 0.162594 [32000 / 60000]\n",
            "loss: 0.071631 [38400 / 60000]\n",
            "loss: 0.088283 [44800 / 60000]\n",
            "loss: 0.147506 [51200 / 60000]\n",
            "loss: 0.095553 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.2% Avg loss 0.006583 \n",
            "\n",
            "epoch 36 \n",
            " --------------------------\n",
            "loss: 0.108704 [    0 / 60000]\n",
            "loss: 0.085478 [ 6400 / 60000]\n",
            "loss: 0.052450 [12800 / 60000]\n",
            "loss: 0.072115 [19200 / 60000]\n",
            "loss: 0.116313 [25600 / 60000]\n",
            "loss: 0.169680 [32000 / 60000]\n",
            "loss: 0.060950 [38400 / 60000]\n",
            "loss: 0.098686 [44800 / 60000]\n",
            "loss: 0.158457 [51200 / 60000]\n",
            "loss: 0.090587 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.0% Avg loss 0.006967 \n",
            "\n",
            "epoch 37 \n",
            " --------------------------\n",
            "loss: 0.097990 [    0 / 60000]\n",
            "loss: 0.105272 [ 6400 / 60000]\n",
            "loss: 0.067443 [12800 / 60000]\n",
            "loss: 0.063724 [19200 / 60000]\n",
            "loss: 0.105403 [25600 / 60000]\n",
            "loss: 0.148864 [32000 / 60000]\n",
            "loss: 0.072523 [38400 / 60000]\n",
            "loss: 0.096173 [44800 / 60000]\n",
            "loss: 0.111553 [51200 / 60000]\n",
            "loss: 0.112326 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.8% Avg loss 0.007131 \n",
            "\n",
            "epoch 38 \n",
            " --------------------------\n",
            "loss: 0.123314 [    0 / 60000]\n",
            "loss: 0.091703 [ 6400 / 60000]\n",
            "loss: 0.088472 [12800 / 60000]\n",
            "loss: 0.081675 [19200 / 60000]\n",
            "loss: 0.097875 [25600 / 60000]\n",
            "loss: 0.153555 [32000 / 60000]\n",
            "loss: 0.051604 [38400 / 60000]\n",
            "loss: 0.074691 [44800 / 60000]\n",
            "loss: 0.137513 [51200 / 60000]\n",
            "loss: 0.112856 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.006963 \n",
            "\n",
            "epoch 39 \n",
            " --------------------------\n",
            "loss: 0.095162 [    0 / 60000]\n",
            "loss: 0.069133 [ 6400 / 60000]\n",
            "loss: 0.064585 [12800 / 60000]\n",
            "loss: 0.134464 [19200 / 60000]\n",
            "loss: 0.107019 [25600 / 60000]\n",
            "loss: 0.144689 [32000 / 60000]\n",
            "loss: 0.058209 [38400 / 60000]\n",
            "loss: 0.093881 [44800 / 60000]\n",
            "loss: 0.134339 [51200 / 60000]\n",
            "loss: 0.133030 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.0% Avg loss 0.006864 \n",
            "\n",
            "epoch 40 \n",
            " --------------------------\n",
            "loss: 0.091385 [    0 / 60000]\n",
            "loss: 0.094302 [ 6400 / 60000]\n",
            "loss: 0.047288 [12800 / 60000]\n",
            "loss: 0.049424 [19200 / 60000]\n",
            "loss: 0.089235 [25600 / 60000]\n",
            "loss: 0.138124 [32000 / 60000]\n",
            "loss: 0.056037 [38400 / 60000]\n",
            "loss: 0.097979 [44800 / 60000]\n",
            "loss: 0.180859 [51200 / 60000]\n",
            "loss: 0.079927 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.1% Avg loss 0.006924 \n",
            "\n",
            "epoch 41 \n",
            " --------------------------\n",
            "loss: 0.101591 [    0 / 60000]\n",
            "loss: 0.067402 [ 6400 / 60000]\n",
            "loss: 0.092547 [12800 / 60000]\n",
            "loss: 0.047977 [19200 / 60000]\n",
            "loss: 0.089518 [25600 / 60000]\n",
            "loss: 0.131024 [32000 / 60000]\n",
            "loss: 0.052274 [38400 / 60000]\n",
            "loss: 0.067487 [44800 / 60000]\n",
            "loss: 0.219122 [51200 / 60000]\n",
            "loss: 0.078179 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.7% Avg loss 0.007256 \n",
            "\n",
            "epoch 42 \n",
            " --------------------------\n",
            "loss: 0.130717 [    0 / 60000]\n",
            "loss: 0.059734 [ 6400 / 60000]\n",
            "loss: 0.057910 [12800 / 60000]\n",
            "loss: 0.032768 [19200 / 60000]\n",
            "loss: 0.181733 [25600 / 60000]\n",
            "loss: 0.114376 [32000 / 60000]\n",
            "loss: 0.046990 [38400 / 60000]\n",
            "loss: 0.085072 [44800 / 60000]\n",
            "loss: 0.079584 [51200 / 60000]\n",
            "loss: 0.066421 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.007156 \n",
            "\n",
            "epoch 43 \n",
            " --------------------------\n",
            "loss: 0.081368 [    0 / 60000]\n",
            "loss: 0.055455 [ 6400 / 60000]\n",
            "loss: 0.059896 [12800 / 60000]\n",
            "loss: 0.044758 [19200 / 60000]\n",
            "loss: 0.088191 [25600 / 60000]\n",
            "loss: 0.139331 [32000 / 60000]\n",
            "loss: 0.036590 [38400 / 60000]\n",
            "loss: 0.082449 [44800 / 60000]\n",
            "loss: 0.109263 [51200 / 60000]\n",
            "loss: 0.057197 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.2% Avg loss 0.007387 \n",
            "\n",
            "epoch 44 \n",
            " --------------------------\n",
            "loss: 0.070075 [    0 / 60000]\n",
            "loss: 0.032685 [ 6400 / 60000]\n",
            "loss: 0.041223 [12800 / 60000]\n",
            "loss: 0.028424 [19200 / 60000]\n",
            "loss: 0.060976 [25600 / 60000]\n",
            "loss: 0.123461 [32000 / 60000]\n",
            "loss: 0.043627 [38400 / 60000]\n",
            "loss: 0.047187 [44800 / 60000]\n",
            "loss: 0.061520 [51200 / 60000]\n",
            "loss: 0.084520 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.1% Avg loss 0.008166 \n",
            "\n",
            "epoch 45 \n",
            " --------------------------\n",
            "loss: 0.141958 [    0 / 60000]\n",
            "loss: 0.097205 [ 6400 / 60000]\n",
            "loss: 0.027339 [12800 / 60000]\n",
            "loss: 0.035306 [19200 / 60000]\n",
            "loss: 0.070892 [25600 / 60000]\n",
            "loss: 0.106880 [32000 / 60000]\n",
            "loss: 0.040265 [38400 / 60000]\n",
            "loss: 0.036980 [44800 / 60000]\n",
            "loss: 0.050836 [51200 / 60000]\n",
            "loss: 0.045274 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.1% Avg loss 0.007326 \n",
            "\n",
            "epoch 46 \n",
            " --------------------------\n",
            "loss: 0.071026 [    0 / 60000]\n",
            "loss: 0.061737 [ 6400 / 60000]\n",
            "loss: 0.033018 [12800 / 60000]\n",
            "loss: 0.029806 [19200 / 60000]\n",
            "loss: 0.094165 [25600 / 60000]\n",
            "loss: 0.111925 [32000 / 60000]\n",
            "loss: 0.033934 [38400 / 60000]\n",
            "loss: 0.039784 [44800 / 60000]\n",
            "loss: 0.093014 [51200 / 60000]\n",
            "loss: 0.036360 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.4% Avg loss 0.007538 \n",
            "\n",
            "epoch 47 \n",
            " --------------------------\n",
            "loss: 0.066307 [    0 / 60000]\n",
            "loss: 0.044124 [ 6400 / 60000]\n",
            "loss: 0.036554 [12800 / 60000]\n",
            "loss: 0.020120 [19200 / 60000]\n",
            "loss: 0.060313 [25600 / 60000]\n",
            "loss: 0.143600 [32000 / 60000]\n",
            "loss: 0.047052 [38400 / 60000]\n",
            "loss: 0.049961 [44800 / 60000]\n",
            "loss: 0.062960 [51200 / 60000]\n",
            "loss: 0.043340 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.7% Avg loss 0.007867 \n",
            "\n",
            "epoch 48 \n",
            " --------------------------\n",
            "loss: 0.067082 [    0 / 60000]\n",
            "loss: 0.063804 [ 6400 / 60000]\n",
            "loss: 0.011126 [12800 / 60000]\n",
            "loss: 0.033550 [19200 / 60000]\n",
            "loss: 0.102365 [25600 / 60000]\n",
            "loss: 0.071814 [32000 / 60000]\n",
            "loss: 0.022554 [38400 / 60000]\n",
            "loss: 0.046513 [44800 / 60000]\n",
            "loss: 0.060902 [51200 / 60000]\n",
            "loss: 0.044575 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.007997 \n",
            "\n",
            "epoch 49 \n",
            " --------------------------\n",
            "loss: 0.098267 [    0 / 60000]\n",
            "loss: 0.056656 [ 6400 / 60000]\n",
            "loss: 0.029825 [12800 / 60000]\n",
            "loss: 0.035781 [19200 / 60000]\n",
            "loss: 0.063103 [25600 / 60000]\n",
            "loss: 0.086260 [32000 / 60000]\n",
            "loss: 0.034641 [38400 / 60000]\n",
            "loss: 0.027716 [44800 / 60000]\n",
            "loss: 0.040850 [51200 / 60000]\n",
            "loss: 0.091786 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.4% Avg loss 0.007981 \n",
            "\n",
            "epoch 50 \n",
            " --------------------------\n",
            "loss: 0.052272 [    0 / 60000]\n",
            "loss: 0.038798 [ 6400 / 60000]\n",
            "loss: 0.028580 [12800 / 60000]\n",
            "loss: 0.014997 [19200 / 60000]\n",
            "loss: 0.051790 [25600 / 60000]\n",
            "loss: 0.114212 [32000 / 60000]\n",
            "loss: 0.036439 [38400 / 60000]\n",
            "loss: 0.028609 [44800 / 60000]\n",
            "loss: 0.049130 [51200 / 60000]\n",
            "loss: 0.046999 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.008018 \n",
            "\n",
            "epoch 51 \n",
            " --------------------------\n",
            "loss: 0.063633 [    0 / 60000]\n",
            "loss: 0.041256 [ 6400 / 60000]\n",
            "loss: 0.024546 [12800 / 60000]\n",
            "loss: 0.022738 [19200 / 60000]\n",
            "loss: 0.083086 [25600 / 60000]\n",
            "loss: 0.095360 [32000 / 60000]\n",
            "loss: 0.024829 [38400 / 60000]\n",
            "loss: 0.045264 [44800 / 60000]\n",
            "loss: 0.058175 [51200 / 60000]\n",
            "loss: 0.043004 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.008385 \n",
            "\n",
            "epoch 52 \n",
            " --------------------------\n",
            "loss: 0.142486 [    0 / 60000]\n",
            "loss: 0.062668 [ 6400 / 60000]\n",
            "loss: 0.062929 [12800 / 60000]\n",
            "loss: 0.024585 [19200 / 60000]\n",
            "loss: 0.035575 [25600 / 60000]\n",
            "loss: 0.062846 [32000 / 60000]\n",
            "loss: 0.045900 [38400 / 60000]\n",
            "loss: 0.065473 [44800 / 60000]\n",
            "loss: 0.049421 [51200 / 60000]\n",
            "loss: 0.030492 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.008454 \n",
            "\n",
            "epoch 53 \n",
            " --------------------------\n",
            "loss: 0.080856 [    0 / 60000]\n",
            "loss: 0.073845 [ 6400 / 60000]\n",
            "loss: 0.039190 [12800 / 60000]\n",
            "loss: 0.041222 [19200 / 60000]\n",
            "loss: 0.034075 [25600 / 60000]\n",
            "loss: 0.056530 [32000 / 60000]\n",
            "loss: 0.022086 [38400 / 60000]\n",
            "loss: 0.020812 [44800 / 60000]\n",
            "loss: 0.124684 [51200 / 60000]\n",
            "loss: 0.032063 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.1% Avg loss 0.008664 \n",
            "\n",
            "epoch 54 \n",
            " --------------------------\n",
            "loss: 0.061331 [    0 / 60000]\n",
            "loss: 0.080119 [ 6400 / 60000]\n",
            "loss: 0.055618 [12800 / 60000]\n",
            "loss: 0.037507 [19200 / 60000]\n",
            "loss: 0.143984 [25600 / 60000]\n",
            "loss: 0.119843 [32000 / 60000]\n",
            "loss: 0.028642 [38400 / 60000]\n",
            "loss: 0.105588 [44800 / 60000]\n",
            "loss: 0.034638 [51200 / 60000]\n",
            "loss: 0.144841 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.008370 \n",
            "\n",
            "epoch 55 \n",
            " --------------------------\n",
            "loss: 0.056040 [    0 / 60000]\n",
            "loss: 0.042653 [ 6400 / 60000]\n",
            "loss: 0.023265 [12800 / 60000]\n",
            "loss: 0.074744 [19200 / 60000]\n",
            "loss: 0.038021 [25600 / 60000]\n",
            "loss: 0.082046 [32000 / 60000]\n",
            "loss: 0.051143 [38400 / 60000]\n",
            "loss: 0.023737 [44800 / 60000]\n",
            "loss: 0.031328 [51200 / 60000]\n",
            "loss: 0.058036 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.008561 \n",
            "\n",
            "epoch 56 \n",
            " --------------------------\n",
            "loss: 0.085366 [    0 / 60000]\n",
            "loss: 0.028462 [ 6400 / 60000]\n",
            "loss: 0.029441 [12800 / 60000]\n",
            "loss: 0.025905 [19200 / 60000]\n",
            "loss: 0.048246 [25600 / 60000]\n",
            "loss: 0.085632 [32000 / 60000]\n",
            "loss: 0.024423 [38400 / 60000]\n",
            "loss: 0.045487 [44800 / 60000]\n",
            "loss: 0.042839 [51200 / 60000]\n",
            "loss: 0.084617 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.4% Avg loss 0.008382 \n",
            "\n",
            "epoch 57 \n",
            " --------------------------\n",
            "loss: 0.069810 [    0 / 60000]\n",
            "loss: 0.023864 [ 6400 / 60000]\n",
            "loss: 0.015270 [12800 / 60000]\n",
            "loss: 0.016664 [19200 / 60000]\n",
            "loss: 0.238650 [25600 / 60000]\n",
            "loss: 0.067309 [32000 / 60000]\n",
            "loss: 0.068695 [38400 / 60000]\n",
            "loss: 0.044761 [44800 / 60000]\n",
            "loss: 0.109447 [51200 / 60000]\n",
            "loss: 0.048803 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 86.7% Avg loss 0.009507 \n",
            "\n",
            "epoch 58 \n",
            " --------------------------\n",
            "loss: 0.099511 [    0 / 60000]\n",
            "loss: 0.067740 [ 6400 / 60000]\n",
            "loss: 0.023657 [12800 / 60000]\n",
            "loss: 0.027816 [19200 / 60000]\n",
            "loss: 0.063026 [25600 / 60000]\n",
            "loss: 0.099801 [32000 / 60000]\n",
            "loss: 0.028796 [38400 / 60000]\n",
            "loss: 0.023544 [44800 / 60000]\n",
            "loss: 0.048052 [51200 / 60000]\n",
            "loss: 0.051635 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.008959 \n",
            "\n",
            "epoch 59 \n",
            " --------------------------\n",
            "loss: 0.121361 [    0 / 60000]\n",
            "loss: 0.037779 [ 6400 / 60000]\n",
            "loss: 0.019111 [12800 / 60000]\n",
            "loss: 0.024613 [19200 / 60000]\n",
            "loss: 0.050290 [25600 / 60000]\n",
            "loss: 0.070570 [32000 / 60000]\n",
            "loss: 0.007309 [38400 / 60000]\n",
            "loss: 0.063717 [44800 / 60000]\n",
            "loss: 0.040128 [51200 / 60000]\n",
            "loss: 0.064461 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.0% Avg loss 0.009615 \n",
            "\n",
            "epoch 60 \n",
            " --------------------------\n",
            "loss: 0.071329 [    0 / 60000]\n",
            "loss: 0.053174 [ 6400 / 60000]\n",
            "loss: 0.062008 [12800 / 60000]\n",
            "loss: 0.023778 [19200 / 60000]\n",
            "loss: 0.031705 [25600 / 60000]\n",
            "loss: 0.041732 [32000 / 60000]\n",
            "loss: 0.026781 [38400 / 60000]\n",
            "loss: 0.034658 [44800 / 60000]\n",
            "loss: 0.115256 [51200 / 60000]\n",
            "loss: 0.040222 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.008797 \n",
            "\n",
            "epoch 61 \n",
            " --------------------------\n",
            "loss: 0.047959 [    0 / 60000]\n",
            "loss: 0.028603 [ 6400 / 60000]\n",
            "loss: 0.018280 [12800 / 60000]\n",
            "loss: 0.025297 [19200 / 60000]\n",
            "loss: 0.029762 [25600 / 60000]\n",
            "loss: 0.051341 [32000 / 60000]\n",
            "loss: 0.026426 [38400 / 60000]\n",
            "loss: 0.017508 [44800 / 60000]\n",
            "loss: 0.027926 [51200 / 60000]\n",
            "loss: 0.050851 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.008982 \n",
            "\n",
            "epoch 62 \n",
            " --------------------------\n",
            "loss: 0.074040 [    0 / 60000]\n",
            "loss: 0.087494 [ 6400 / 60000]\n",
            "loss: 0.049419 [12800 / 60000]\n",
            "loss: 0.016206 [19200 / 60000]\n",
            "loss: 0.042573 [25600 / 60000]\n",
            "loss: 0.068768 [32000 / 60000]\n",
            "loss: 0.047522 [38400 / 60000]\n",
            "loss: 0.092152 [44800 / 60000]\n",
            "loss: 0.021980 [51200 / 60000]\n",
            "loss: 0.064145 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.009061 \n",
            "\n",
            "epoch 63 \n",
            " --------------------------\n",
            "loss: 0.073882 [    0 / 60000]\n",
            "loss: 0.019668 [ 6400 / 60000]\n",
            "loss: 0.020015 [12800 / 60000]\n",
            "loss: 0.078696 [19200 / 60000]\n",
            "loss: 0.049398 [25600 / 60000]\n",
            "loss: 0.066955 [32000 / 60000]\n",
            "loss: 0.020883 [38400 / 60000]\n",
            "loss: 0.016077 [44800 / 60000]\n",
            "loss: 0.051884 [51200 / 60000]\n",
            "loss: 0.056272 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.009308 \n",
            "\n",
            "epoch 64 \n",
            " --------------------------\n",
            "loss: 0.030674 [    0 / 60000]\n",
            "loss: 0.017830 [ 6400 / 60000]\n",
            "loss: 0.020815 [12800 / 60000]\n",
            "loss: 0.027381 [19200 / 60000]\n",
            "loss: 0.040600 [25600 / 60000]\n",
            "loss: 0.050551 [32000 / 60000]\n",
            "loss: 0.061006 [38400 / 60000]\n",
            "loss: 0.019812 [44800 / 60000]\n",
            "loss: 0.015120 [51200 / 60000]\n",
            "loss: 0.020805 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.009372 \n",
            "\n",
            "epoch 65 \n",
            " --------------------------\n",
            "loss: 0.054674 [    0 / 60000]\n",
            "loss: 0.037287 [ 6400 / 60000]\n",
            "loss: 0.031989 [12800 / 60000]\n",
            "loss: 0.017693 [19200 / 60000]\n",
            "loss: 0.026369 [25600 / 60000]\n",
            "loss: 0.045517 [32000 / 60000]\n",
            "loss: 0.038168 [38400 / 60000]\n",
            "loss: 0.003121 [44800 / 60000]\n",
            "loss: 0.034160 [51200 / 60000]\n",
            "loss: 0.114202 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.7% Avg loss 0.009280 \n",
            "\n",
            "epoch 66 \n",
            " --------------------------\n",
            "loss: 0.092853 [    0 / 60000]\n",
            "loss: 0.041688 [ 6400 / 60000]\n",
            "loss: 0.009851 [12800 / 60000]\n",
            "loss: 0.015454 [19200 / 60000]\n",
            "loss: 0.024633 [25600 / 60000]\n",
            "loss: 0.072531 [32000 / 60000]\n",
            "loss: 0.268723 [38400 / 60000]\n",
            "loss: 0.011866 [44800 / 60000]\n",
            "loss: 0.012858 [51200 / 60000]\n",
            "loss: 0.039264 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.009338 \n",
            "\n",
            "epoch 67 \n",
            " --------------------------\n",
            "loss: 0.052337 [    0 / 60000]\n",
            "loss: 0.055106 [ 6400 / 60000]\n",
            "loss: 0.009333 [12800 / 60000]\n",
            "loss: 0.016306 [19200 / 60000]\n",
            "loss: 0.082752 [25600 / 60000]\n",
            "loss: 0.027446 [32000 / 60000]\n",
            "loss: 0.021635 [38400 / 60000]\n",
            "loss: 0.026718 [44800 / 60000]\n",
            "loss: 0.039921 [51200 / 60000]\n",
            "loss: 0.023052 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.2% Avg loss 0.009956 \n",
            "\n",
            "epoch 68 \n",
            " --------------------------\n",
            "loss: 0.074588 [    0 / 60000]\n",
            "loss: 0.023358 [ 6400 / 60000]\n",
            "loss: 0.006695 [12800 / 60000]\n",
            "loss: 0.018620 [19200 / 60000]\n",
            "loss: 0.025337 [25600 / 60000]\n",
            "loss: 0.039978 [32000 / 60000]\n",
            "loss: 0.025085 [38400 / 60000]\n",
            "loss: 0.032801 [44800 / 60000]\n",
            "loss: 0.052555 [51200 / 60000]\n",
            "loss: 0.076719 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.1% Avg loss 0.010514 \n",
            "\n",
            "epoch 69 \n",
            " --------------------------\n",
            "loss: 0.095991 [    0 / 60000]\n",
            "loss: 0.008079 [ 6400 / 60000]\n",
            "loss: 0.009297 [12800 / 60000]\n",
            "loss: 0.027885 [19200 / 60000]\n",
            "loss: 0.068556 [25600 / 60000]\n",
            "loss: 0.049079 [32000 / 60000]\n",
            "loss: 0.024228 [38400 / 60000]\n",
            "loss: 0.013391 [44800 / 60000]\n",
            "loss: 0.022672 [51200 / 60000]\n",
            "loss: 0.061504 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.009658 \n",
            "\n",
            "epoch 70 \n",
            " --------------------------\n",
            "loss: 0.056461 [    0 / 60000]\n",
            "loss: 0.124175 [ 6400 / 60000]\n",
            "loss: 0.042873 [12800 / 60000]\n",
            "loss: 0.072029 [19200 / 60000]\n",
            "loss: 0.010270 [25600 / 60000]\n",
            "loss: 0.044044 [32000 / 60000]\n",
            "loss: 0.011380 [38400 / 60000]\n",
            "loss: 0.021037 [44800 / 60000]\n",
            "loss: 0.211176 [51200 / 60000]\n",
            "loss: 0.019735 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.9% Avg loss 0.010724 \n",
            "\n",
            "epoch 71 \n",
            " --------------------------\n",
            "loss: 0.100102 [    0 / 60000]\n",
            "loss: 0.056199 [ 6400 / 60000]\n",
            "loss: 0.043255 [12800 / 60000]\n",
            "loss: 0.020664 [19200 / 60000]\n",
            "loss: 0.043424 [25600 / 60000]\n",
            "loss: 0.068940 [32000 / 60000]\n",
            "loss: 0.012414 [38400 / 60000]\n",
            "loss: 0.017383 [44800 / 60000]\n",
            "loss: 0.032424 [51200 / 60000]\n",
            "loss: 0.051268 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.010434 \n",
            "\n",
            "epoch 72 \n",
            " --------------------------\n",
            "loss: 0.040871 [    0 / 60000]\n",
            "loss: 0.019216 [ 6400 / 60000]\n",
            "loss: 0.028577 [12800 / 60000]\n",
            "loss: 0.046033 [19200 / 60000]\n",
            "loss: 0.032677 [25600 / 60000]\n",
            "loss: 0.031242 [32000 / 60000]\n",
            "loss: 0.014210 [38400 / 60000]\n",
            "loss: 0.018635 [44800 / 60000]\n",
            "loss: 0.020579 [51200 / 60000]\n",
            "loss: 0.069599 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.009989 \n",
            "\n",
            "epoch 73 \n",
            " --------------------------\n",
            "loss: 0.024166 [    0 / 60000]\n",
            "loss: 0.014287 [ 6400 / 60000]\n",
            "loss: 0.008547 [12800 / 60000]\n",
            "loss: 0.011632 [19200 / 60000]\n",
            "loss: 0.047666 [25600 / 60000]\n",
            "loss: 0.043160 [32000 / 60000]\n",
            "loss: 0.009263 [38400 / 60000]\n",
            "loss: 0.023817 [44800 / 60000]\n",
            "loss: 0.059226 [51200 / 60000]\n",
            "loss: 0.024190 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.010468 \n",
            "\n",
            "epoch 74 \n",
            " --------------------------\n",
            "loss: 0.064213 [    0 / 60000]\n",
            "loss: 0.021256 [ 6400 / 60000]\n",
            "loss: 0.028388 [12800 / 60000]\n",
            "loss: 0.016180 [19200 / 60000]\n",
            "loss: 0.028505 [25600 / 60000]\n",
            "loss: 0.029854 [32000 / 60000]\n",
            "loss: 0.019208 [38400 / 60000]\n",
            "loss: 0.007331 [44800 / 60000]\n",
            "loss: 0.043754 [51200 / 60000]\n",
            "loss: 0.008732 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.010294 \n",
            "\n",
            "epoch 75 \n",
            " --------------------------\n",
            "loss: 0.027120 [    0 / 60000]\n",
            "loss: 0.026541 [ 6400 / 60000]\n",
            "loss: 0.023446 [12800 / 60000]\n",
            "loss: 0.006174 [19200 / 60000]\n",
            "loss: 0.010008 [25600 / 60000]\n",
            "loss: 0.072480 [32000 / 60000]\n",
            "loss: 0.024481 [38400 / 60000]\n",
            "loss: 0.020963 [44800 / 60000]\n",
            "loss: 0.040447 [51200 / 60000]\n",
            "loss: 0.050098 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.010531 \n",
            "\n",
            "epoch 76 \n",
            " --------------------------\n",
            "loss: 0.050663 [    0 / 60000]\n",
            "loss: 0.016385 [ 6400 / 60000]\n",
            "loss: 0.009938 [12800 / 60000]\n",
            "loss: 0.013083 [19200 / 60000]\n",
            "loss: 0.106323 [25600 / 60000]\n",
            "loss: 0.045055 [32000 / 60000]\n",
            "loss: 0.024280 [38400 / 60000]\n",
            "loss: 0.029209 [44800 / 60000]\n",
            "loss: 0.028523 [51200 / 60000]\n",
            "loss: 0.014359 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.010455 \n",
            "\n",
            "epoch 77 \n",
            " --------------------------\n",
            "loss: 0.044978 [    0 / 60000]\n",
            "loss: 0.027573 [ 6400 / 60000]\n",
            "loss: 0.014072 [12800 / 60000]\n",
            "loss: 0.036160 [19200 / 60000]\n",
            "loss: 0.069129 [25600 / 60000]\n",
            "loss: 0.085163 [32000 / 60000]\n",
            "loss: 0.014855 [38400 / 60000]\n",
            "loss: 0.003603 [44800 / 60000]\n",
            "loss: 0.057773 [51200 / 60000]\n",
            "loss: 0.030284 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.010282 \n",
            "\n",
            "epoch 78 \n",
            " --------------------------\n",
            "loss: 0.019983 [    0 / 60000]\n",
            "loss: 0.015590 [ 6400 / 60000]\n",
            "loss: 0.007818 [12800 / 60000]\n",
            "loss: 0.008523 [19200 / 60000]\n",
            "loss: 0.035472 [25600 / 60000]\n",
            "loss: 0.020599 [32000 / 60000]\n",
            "loss: 0.023131 [38400 / 60000]\n",
            "loss: 0.010188 [44800 / 60000]\n",
            "loss: 0.025191 [51200 / 60000]\n",
            "loss: 0.009267 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.7% Avg loss 0.010135 \n",
            "\n",
            "epoch 79 \n",
            " --------------------------\n",
            "loss: 0.024962 [    0 / 60000]\n",
            "loss: 0.040521 [ 6400 / 60000]\n",
            "loss: 0.048303 [12800 / 60000]\n",
            "loss: 0.045516 [19200 / 60000]\n",
            "loss: 0.012572 [25600 / 60000]\n",
            "loss: 0.043122 [32000 / 60000]\n",
            "loss: 0.023412 [38400 / 60000]\n",
            "loss: 0.011431 [44800 / 60000]\n",
            "loss: 0.047384 [51200 / 60000]\n",
            "loss: 0.021744 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.010344 \n",
            "\n",
            "epoch 80 \n",
            " --------------------------\n",
            "loss: 0.009170 [    0 / 60000]\n",
            "loss: 0.021721 [ 6400 / 60000]\n",
            "loss: 0.018987 [12800 / 60000]\n",
            "loss: 0.013934 [19200 / 60000]\n",
            "loss: 0.086905 [25600 / 60000]\n",
            "loss: 0.034350 [32000 / 60000]\n",
            "loss: 0.030679 [38400 / 60000]\n",
            "loss: 0.029349 [44800 / 60000]\n",
            "loss: 0.074735 [51200 / 60000]\n",
            "loss: 0.034796 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.2% Avg loss 0.010947 \n",
            "\n",
            "epoch 81 \n",
            " --------------------------\n",
            "loss: 0.021879 [    0 / 60000]\n",
            "loss: 0.033810 [ 6400 / 60000]\n",
            "loss: 0.009237 [12800 / 60000]\n",
            "loss: 0.014941 [19200 / 60000]\n",
            "loss: 0.020569 [25600 / 60000]\n",
            "loss: 0.023169 [32000 / 60000]\n",
            "loss: 0.013284 [38400 / 60000]\n",
            "loss: 0.014139 [44800 / 60000]\n",
            "loss: 0.032635 [51200 / 60000]\n",
            "loss: 0.159027 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 87.8% Avg loss 0.011596 \n",
            "\n",
            "epoch 82 \n",
            " --------------------------\n",
            "loss: 0.053433 [    0 / 60000]\n",
            "loss: 0.009586 [ 6400 / 60000]\n",
            "loss: 0.018316 [12800 / 60000]\n",
            "loss: 0.011721 [19200 / 60000]\n",
            "loss: 0.055844 [25600 / 60000]\n",
            "loss: 0.041278 [32000 / 60000]\n",
            "loss: 0.052213 [38400 / 60000]\n",
            "loss: 0.014279 [44800 / 60000]\n",
            "loss: 0.022693 [51200 / 60000]\n",
            "loss: 0.016814 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.010520 \n",
            "\n",
            "epoch 83 \n",
            " --------------------------\n",
            "loss: 0.033392 [    0 / 60000]\n",
            "loss: 0.100146 [ 6400 / 60000]\n",
            "loss: 0.042406 [12800 / 60000]\n",
            "loss: 0.026441 [19200 / 60000]\n",
            "loss: 0.016669 [25600 / 60000]\n",
            "loss: 0.037153 [32000 / 60000]\n",
            "loss: 0.010157 [38400 / 60000]\n",
            "loss: 0.003012 [44800 / 60000]\n",
            "loss: 0.056578 [51200 / 60000]\n",
            "loss: 0.026295 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.3% Avg loss 0.011461 \n",
            "\n",
            "epoch 84 \n",
            " --------------------------\n",
            "loss: 0.014641 [    0 / 60000]\n",
            "loss: 0.031430 [ 6400 / 60000]\n",
            "loss: 0.015460 [12800 / 60000]\n",
            "loss: 0.017794 [19200 / 60000]\n",
            "loss: 0.105208 [25600 / 60000]\n",
            "loss: 0.015435 [32000 / 60000]\n",
            "loss: 0.010421 [38400 / 60000]\n",
            "loss: 0.025499 [44800 / 60000]\n",
            "loss: 0.020413 [51200 / 60000]\n",
            "loss: 0.012336 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.010707 \n",
            "\n",
            "epoch 85 \n",
            " --------------------------\n",
            "loss: 0.006194 [    0 / 60000]\n",
            "loss: 0.015493 [ 6400 / 60000]\n",
            "loss: 0.044117 [12800 / 60000]\n",
            "loss: 0.017436 [19200 / 60000]\n",
            "loss: 0.006956 [25600 / 60000]\n",
            "loss: 0.046254 [32000 / 60000]\n",
            "loss: 0.014542 [38400 / 60000]\n",
            "loss: 0.011487 [44800 / 60000]\n",
            "loss: 0.010833 [51200 / 60000]\n",
            "loss: 0.012024 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.7% Avg loss 0.010946 \n",
            "\n",
            "epoch 86 \n",
            " --------------------------\n",
            "loss: 0.055567 [    0 / 60000]\n",
            "loss: 0.008066 [ 6400 / 60000]\n",
            "loss: 0.007897 [12800 / 60000]\n",
            "loss: 0.022490 [19200 / 60000]\n",
            "loss: 0.046124 [25600 / 60000]\n",
            "loss: 0.069742 [32000 / 60000]\n",
            "loss: 0.012059 [38400 / 60000]\n",
            "loss: 0.006116 [44800 / 60000]\n",
            "loss: 0.012666 [51200 / 60000]\n",
            "loss: 0.029333 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 89.2% Avg loss 0.010343 \n",
            "\n",
            "epoch 87 \n",
            " --------------------------\n",
            "loss: 0.020381 [    0 / 60000]\n",
            "loss: 0.050601 [ 6400 / 60000]\n",
            "loss: 0.007010 [12800 / 60000]\n",
            "loss: 0.021504 [19200 / 60000]\n",
            "loss: 0.010506 [25600 / 60000]\n",
            "loss: 0.033274 [32000 / 60000]\n",
            "loss: 0.017359 [38400 / 60000]\n",
            "loss: 0.017714 [44800 / 60000]\n",
            "loss: 0.070591 [51200 / 60000]\n",
            "loss: 0.006832 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.9% Avg loss 0.010748 \n",
            "\n",
            "epoch 88 \n",
            " --------------------------\n",
            "loss: 0.012650 [    0 / 60000]\n",
            "loss: 0.004587 [ 6400 / 60000]\n",
            "loss: 0.020220 [12800 / 60000]\n",
            "loss: 0.008398 [19200 / 60000]\n",
            "loss: 0.010234 [25600 / 60000]\n",
            "loss: 0.012039 [32000 / 60000]\n",
            "loss: 0.019048 [38400 / 60000]\n",
            "loss: 0.027775 [44800 / 60000]\n",
            "loss: 0.043050 [51200 / 60000]\n",
            "loss: 0.053490 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.9% Avg loss 0.010861 \n",
            "\n",
            "epoch 89 \n",
            " --------------------------\n",
            "loss: 0.027058 [    0 / 60000]\n",
            "loss: 0.021217 [ 6400 / 60000]\n",
            "loss: 0.009838 [12800 / 60000]\n",
            "loss: 0.009031 [19200 / 60000]\n",
            "loss: 0.021374 [25600 / 60000]\n",
            "loss: 0.025614 [32000 / 60000]\n",
            "loss: 0.010400 [38400 / 60000]\n",
            "loss: 0.104395 [44800 / 60000]\n",
            "loss: 0.008941 [51200 / 60000]\n",
            "loss: 0.009424 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.010859 \n",
            "\n",
            "epoch 90 \n",
            " --------------------------\n",
            "loss: 0.020794 [    0 / 60000]\n",
            "loss: 0.006742 [ 6400 / 60000]\n",
            "loss: 0.017223 [12800 / 60000]\n",
            "loss: 0.012569 [19200 / 60000]\n",
            "loss: 0.016008 [25600 / 60000]\n",
            "loss: 0.015703 [32000 / 60000]\n",
            "loss: 0.013941 [38400 / 60000]\n",
            "loss: 0.001509 [44800 / 60000]\n",
            "loss: 0.036373 [51200 / 60000]\n",
            "loss: 0.004464 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.7% Avg loss 0.011112 \n",
            "\n",
            "epoch 91 \n",
            " --------------------------\n",
            "loss: 0.018003 [    0 / 60000]\n",
            "loss: 0.042468 [ 6400 / 60000]\n",
            "loss: 0.009898 [12800 / 60000]\n",
            "loss: 0.008386 [19200 / 60000]\n",
            "loss: 0.008925 [25600 / 60000]\n",
            "loss: 0.020861 [32000 / 60000]\n",
            "loss: 0.012958 [38400 / 60000]\n",
            "loss: 0.006362 [44800 / 60000]\n",
            "loss: 0.029275 [51200 / 60000]\n",
            "loss: 0.032101 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.011132 \n",
            "\n",
            "epoch 92 \n",
            " --------------------------\n",
            "loss: 0.049111 [    0 / 60000]\n",
            "loss: 0.018235 [ 6400 / 60000]\n",
            "loss: 0.025486 [12800 / 60000]\n",
            "loss: 0.034953 [19200 / 60000]\n",
            "loss: 0.051387 [25600 / 60000]\n",
            "loss: 0.007102 [32000 / 60000]\n",
            "loss: 0.010520 [38400 / 60000]\n",
            "loss: 0.003353 [44800 / 60000]\n",
            "loss: 0.002210 [51200 / 60000]\n",
            "loss: 0.021496 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.4% Avg loss 0.011386 \n",
            "\n",
            "epoch 93 \n",
            " --------------------------\n",
            "loss: 0.040527 [    0 / 60000]\n",
            "loss: 0.003587 [ 6400 / 60000]\n",
            "loss: 0.005517 [12800 / 60000]\n",
            "loss: 0.003184 [19200 / 60000]\n",
            "loss: 0.084643 [25600 / 60000]\n",
            "loss: 0.045899 [32000 / 60000]\n",
            "loss: 0.020945 [38400 / 60000]\n",
            "loss: 0.008389 [44800 / 60000]\n",
            "loss: 0.056151 [51200 / 60000]\n",
            "loss: 0.010240 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.010744 \n",
            "\n",
            "epoch 94 \n",
            " --------------------------\n",
            "loss: 0.008662 [    0 / 60000]\n",
            "loss: 0.014342 [ 6400 / 60000]\n",
            "loss: 0.011666 [12800 / 60000]\n",
            "loss: 0.076280 [19200 / 60000]\n",
            "loss: 0.039670 [25600 / 60000]\n",
            "loss: 0.010551 [32000 / 60000]\n",
            "loss: 0.005070 [38400 / 60000]\n",
            "loss: 0.009220 [44800 / 60000]\n",
            "loss: 0.003260 [51200 / 60000]\n",
            "loss: 0.005997 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.011651 \n",
            "\n",
            "epoch 95 \n",
            " --------------------------\n",
            "loss: 0.021560 [    0 / 60000]\n",
            "loss: 0.019451 [ 6400 / 60000]\n",
            "loss: 0.001971 [12800 / 60000]\n",
            "loss: 0.011387 [19200 / 60000]\n",
            "loss: 0.016184 [25600 / 60000]\n",
            "loss: 0.035956 [32000 / 60000]\n",
            "loss: 0.046828 [38400 / 60000]\n",
            "loss: 0.017510 [44800 / 60000]\n",
            "loss: 0.033499 [51200 / 60000]\n",
            "loss: 0.017298 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.9% Avg loss 0.011132 \n",
            "\n",
            "epoch 96 \n",
            " --------------------------\n",
            "loss: 0.009840 [    0 / 60000]\n",
            "loss: 0.005821 [ 6400 / 60000]\n",
            "loss: 0.003049 [12800 / 60000]\n",
            "loss: 0.031621 [19200 / 60000]\n",
            "loss: 0.015432 [25600 / 60000]\n",
            "loss: 0.016596 [32000 / 60000]\n",
            "loss: 0.017938 [38400 / 60000]\n",
            "loss: 0.003217 [44800 / 60000]\n",
            "loss: 0.028119 [51200 / 60000]\n",
            "loss: 0.016599 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.7% Avg loss 0.011500 \n",
            "\n",
            "epoch 97 \n",
            " --------------------------\n",
            "loss: 0.025967 [    0 / 60000]\n",
            "loss: 0.034223 [ 6400 / 60000]\n",
            "loss: 0.048179 [12800 / 60000]\n",
            "loss: 0.008879 [19200 / 60000]\n",
            "loss: 0.026679 [25600 / 60000]\n",
            "loss: 0.016645 [32000 / 60000]\n",
            "loss: 0.011667 [38400 / 60000]\n",
            "loss: 0.039651 [44800 / 60000]\n",
            "loss: 0.003698 [51200 / 60000]\n",
            "loss: 0.003795 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.011659 \n",
            "\n",
            "epoch 98 \n",
            " --------------------------\n",
            "loss: 0.026045 [    0 / 60000]\n",
            "loss: 0.004395 [ 6400 / 60000]\n",
            "loss: 0.004316 [12800 / 60000]\n",
            "loss: 0.003718 [19200 / 60000]\n",
            "loss: 0.017355 [25600 / 60000]\n",
            "loss: 0.011496 [32000 / 60000]\n",
            "loss: 0.007665 [38400 / 60000]\n",
            "loss: 0.031442 [44800 / 60000]\n",
            "loss: 0.010656 [51200 / 60000]\n",
            "loss: 0.010392 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.5% Avg loss 0.011363 \n",
            "\n",
            "epoch 99 \n",
            " --------------------------\n",
            "loss: 0.016846 [    0 / 60000]\n",
            "loss: 0.056768 [ 6400 / 60000]\n",
            "loss: 0.020440 [12800 / 60000]\n",
            "loss: 0.010358 [19200 / 60000]\n",
            "loss: 0.048837 [25600 / 60000]\n",
            "loss: 0.018270 [32000 / 60000]\n",
            "loss: 0.030467 [38400 / 60000]\n",
            "loss: 0.011375 [44800 / 60000]\n",
            "loss: 0.044865 [51200 / 60000]\n",
            "loss: 0.012415 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.6% Avg loss 0.011498 \n",
            "\n",
            "epoch 100 \n",
            " --------------------------\n",
            "loss: 0.005662 [    0 / 60000]\n",
            "loss: 0.009540 [ 6400 / 60000]\n",
            "loss: 0.001802 [12800 / 60000]\n",
            "loss: 0.005205 [19200 / 60000]\n",
            "loss: 0.006302 [25600 / 60000]\n",
            "loss: 0.036442 [32000 / 60000]\n",
            "loss: 0.032299 [38400 / 60000]\n",
            "loss: 0.012388 [44800 / 60000]\n",
            "loss: 0.003184 [51200 / 60000]\n",
            "loss: 0.021363 [57600 / 60000]\n",
            "Test error: \n",
            " Accuracy 88.8% Avg loss 0.011528 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        "    )\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        "    )\n",
        "\n",
        "print(training_data)\n",
        "print(test_data)\n",
        "\n",
        "train_dataloader = DataLoader(dataset=training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=64)\n",
        "\n",
        "print(train_dataloader)\n",
        "print(test_dataloader)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.liner_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.liner_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "print(model)\n",
        "\n",
        "learing_rate = 0.1\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimazer = torch.optim.SGD(model.parameters(), lr=learing_rate)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimazer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    optimazer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimazer.step()\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d} / {size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= size\n",
        "  correct /= size\n",
        "\n",
        "  print(f\"Test error: \\n Accuracy {100*correct:>0.1f}% Avg loss {test_loss:>8f} \\n\")\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "for i in range(epochs):\n",
        "  print(f\"epoch {i+1} \\n --------------------------\")\n",
        "  train_loop(dataloader = train_dataloader, model = model, loss_fn = loss_fn, optimazer = optimazer)\n",
        "  test_loop(dataloader = test_dataloader, model = model, loss_fn = loss_fn)\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"data/mnist_data_model.pth\"\n",
        "saved_model = NeuralNetwork()\n",
        "saved_model.load_state_dict(torch.load(PATH))\n",
        "saved_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLHs9DEuVJOH",
        "outputId": "e4b45100-e3e6-49bf-a14c-2060e6cfd820"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (liner_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install onnx\n",
        "%pip install onnxruntime-gpu\n",
        "\n",
        "import onnxruntime\n",
        "import torch.onnx as onnx\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_1YQmVQWFXy",
        "outputId": "fb7e1092-7f02-4353-80e0-9866a77b528d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.16.2\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.10/dist-packages (1.18.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imput_image = torch.zeros((1, 28, 28))\n",
        "onnx_model = 'data/model.onnx'\n",
        "onnx.export(saved_model, imput_image, onnx_model)"
      ],
      "metadata": {
        "id": "5X2LmcW4VfVe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "X, y = test_data[1][0], test_data[1][1]"
      ],
      "metadata": {
        "id": "A_5zGalqbkZA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = onnxruntime.InferenceSession(onnx_model, None)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "result = session.run([output_name], {input_name: X.numpy()})\n",
        "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
        "print(f'Predicted; \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ5XJTF2b77B",
        "outputId": "9d07f5b6-f0a9-4192-8f80-9b89570429fb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted; \"Pullover\", Actual: \"Pullover\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O1TI-bXEdE0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}