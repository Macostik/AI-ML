{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO7i8Zlh5TXExsSMUwdl5Zr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HUIcX0TuLbUP","executionInfo":{"status":"ok","timestamp":1723463544464,"user_tz":-180,"elapsed":1082997,"user":{"displayName":"Yura Granchenko","userId":"10944670730732163435"}},"outputId":"b5354d21-b024-4329-8117-600d3998dac5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset FashionMNIST\n","    Number of datapoints: 60000\n","    Root location: data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()\n","Dataset FashionMNIST\n","    Number of datapoints: 10000\n","    Root location: data\n","    Split: Test\n","    StandardTransform\n","Transform: ToTensor()\n","<torch.utils.data.dataloader.DataLoader object at 0x7f562398cf10>\n","<torch.utils.data.dataloader.DataLoader object at 0x7f562398f340>\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (liner_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","    (5): ReLU()\n","  )\n",")\n","epoch 1 \n"," --------------------------\n","loss: 2.304281 [    0 / 60000]\n","loss: 2.300185 [ 6400 / 60000]\n","loss: 2.295037 [12800 / 60000]\n","loss: 2.287416 [19200 / 60000]\n","loss: 2.284033 [25600 / 60000]\n","loss: 2.283469 [32000 / 60000]\n","loss: 2.257445 [38400 / 60000]\n","loss: 2.251000 [44800 / 60000]\n","loss: 2.253856 [51200 / 60000]\n","loss: 2.230295 [57600 / 60000]\n","Test error: \n"," Accuracy 45.6% Avg loss 0.035132 \n","\n","epoch 2 \n"," --------------------------\n","loss: 2.236988 [    0 / 60000]\n","loss: 2.244580 [ 6400 / 60000]\n","loss: 2.229192 [12800 / 60000]\n","loss: 2.234921 [19200 / 60000]\n","loss: 2.181571 [25600 / 60000]\n","loss: 2.200617 [32000 / 60000]\n","loss: 2.152660 [38400 / 60000]\n","loss: 2.143516 [44800 / 60000]\n","loss: 2.170015 [51200 / 60000]\n","loss: 2.113138 [57600 / 60000]\n","Test error: \n"," Accuracy 46.0% Avg loss 0.033529 \n","\n","epoch 3 \n"," --------------------------\n","loss: 2.141028 [    0 / 60000]\n","loss: 2.150670 [ 6400 / 60000]\n","loss: 2.122710 [12800 / 60000]\n","loss: 2.132870 [19200 / 60000]\n","loss: 2.000491 [25600 / 60000]\n","loss: 2.071461 [32000 / 60000]\n","loss: 1.967871 [38400 / 60000]\n","loss: 1.967485 [44800 / 60000]\n","loss: 2.039817 [51200 / 60000]\n","loss: 1.913765 [57600 / 60000]\n","Test error: \n"," Accuracy 47.6% Avg loss 0.030542 \n","\n","epoch 4 \n"," --------------------------\n","loss: 1.992694 [    0 / 60000]\n","loss: 1.973683 [ 6400 / 60000]\n","loss: 1.936617 [12800 / 60000]\n","loss: 1.941913 [19200 / 60000]\n","loss: 1.719837 [25600 / 60000]\n","loss: 1.895746 [32000 / 60000]\n","loss: 1.705064 [38400 / 60000]\n","loss: 1.739902 [44800 / 60000]\n","loss: 1.876663 [51200 / 60000]\n","loss: 1.676966 [57600 / 60000]\n","Test error: \n"," Accuracy 52.3% Avg loss 0.027079 \n","\n","epoch 5 \n"," --------------------------\n","loss: 1.825453 [    0 / 60000]\n","loss: 1.778670 [ 6400 / 60000]\n","loss: 1.751231 [12800 / 60000]\n","loss: 1.741442 [19200 / 60000]\n","loss: 1.464045 [25600 / 60000]\n","loss: 1.750559 [32000 / 60000]\n","loss: 1.478350 [38400 / 60000]\n","loss: 1.561658 [44800 / 60000]\n","loss: 1.732436 [51200 / 60000]\n","loss: 1.502710 [57600 / 60000]\n","Test error: \n"," Accuracy 54.6% Avg loss 0.024404 \n","\n","epoch 6 \n"," --------------------------\n","loss: 1.685249 [    0 / 60000]\n","loss: 1.625386 [ 6400 / 60000]\n","loss: 1.605711 [12800 / 60000]\n","loss: 1.593333 [19200 / 60000]\n","loss: 1.284735 [25600 / 60000]\n","loss: 1.642318 [32000 / 60000]\n","loss: 1.326538 [38400 / 60000]\n","loss: 1.442295 [44800 / 60000]\n","loss: 1.616702 [51200 / 60000]\n","loss: 1.388884 [57600 / 60000]\n","Test error: \n"," Accuracy 55.6% Avg loss 0.022515 \n","\n","epoch 7 \n"," --------------------------\n","loss: 1.572788 [    0 / 60000]\n","loss: 1.514591 [ 6400 / 60000]\n","loss: 1.492711 [12800 / 60000]\n","loss: 1.488587 [19200 / 60000]\n","loss: 1.168456 [25600 / 60000]\n","loss: 1.557113 [32000 / 60000]\n","loss: 1.228272 [38400 / 60000]\n","loss: 1.360353 [44800 / 60000]\n","loss: 1.527757 [51200 / 60000]\n","loss: 1.310846 [57600 / 60000]\n","Test error: \n"," Accuracy 56.5% Avg loss 0.021172 \n","\n","epoch 8 \n"," --------------------------\n","loss: 1.485840 [    0 / 60000]\n","loss: 1.414978 [ 6400 / 60000]\n","loss: 1.333562 [12800 / 60000]\n","loss: 1.360585 [19200 / 60000]\n","loss: 1.079206 [25600 / 60000]\n","loss: 1.409323 [32000 / 60000]\n","loss: 1.110083 [38400 / 60000]\n","loss: 1.194486 [44800 / 60000]\n","loss: 1.295318 [51200 / 60000]\n","loss: 1.257334 [57600 / 60000]\n","Test error: \n"," Accuracy 62.0% Avg loss 0.018917 \n","\n","epoch 9 \n"," --------------------------\n","loss: 1.231755 [    0 / 60000]\n","loss: 1.219961 [ 6400 / 60000]\n","loss: 1.127372 [12800 / 60000]\n","loss: 1.260303 [19200 / 60000]\n","loss: 1.011469 [25600 / 60000]\n","loss: 1.309316 [32000 / 60000]\n","loss: 1.028530 [38400 / 60000]\n","loss: 1.112878 [44800 / 60000]\n","loss: 1.201880 [51200 / 60000]\n","loss: 1.203285 [57600 / 60000]\n","Test error: \n"," Accuracy 64.7% Avg loss 0.017767 \n","\n","epoch 10 \n"," --------------------------\n","loss: 1.126340 [    0 / 60000]\n","loss: 1.138413 [ 6400 / 60000]\n","loss: 1.028728 [12800 / 60000]\n","loss: 1.204891 [19200 / 60000]\n","loss: 0.969031 [25600 / 60000]\n","loss: 1.240332 [32000 / 60000]\n","loss: 0.977085 [38400 / 60000]\n","loss: 1.064706 [44800 / 60000]\n","loss: 1.144186 [51200 / 60000]\n","loss: 1.159459 [57600 / 60000]\n","Test error: \n"," Accuracy 66.4% Avg loss 0.016979 \n","\n","epoch 11 \n"," --------------------------\n","loss: 1.058554 [    0 / 60000]\n","loss: 1.083286 [ 6400 / 60000]\n","loss: 0.963857 [12800 / 60000]\n","loss: 1.166421 [19200 / 60000]\n","loss: 0.939001 [25600 / 60000]\n","loss: 1.190442 [32000 / 60000]\n","loss: 0.940046 [38400 / 60000]\n","loss: 1.032912 [44800 / 60000]\n","loss: 1.103755 [51200 / 60000]\n","loss: 1.124431 [57600 / 60000]\n","Test error: \n"," Accuracy 67.4% Avg loss 0.016393 \n","\n","epoch 12 \n"," --------------------------\n","loss: 1.008578 [    0 / 60000]\n","loss: 1.040736 [ 6400 / 60000]\n","loss: 0.916738 [12800 / 60000]\n","loss: 1.135951 [19200 / 60000]\n","loss: 0.914532 [25600 / 60000]\n","loss: 1.153760 [32000 / 60000]\n","loss: 0.910575 [38400 / 60000]\n","loss: 1.010154 [44800 / 60000]\n","loss: 1.070485 [51200 / 60000]\n","loss: 1.095465 [57600 / 60000]\n","Test error: \n"," Accuracy 68.3% Avg loss 0.015924 \n","\n","epoch 13 \n"," --------------------------\n","loss: 0.968553 [    0 / 60000]\n","loss: 1.005842 [ 6400 / 60000]\n","loss: 0.879816 [12800 / 60000]\n","loss: 1.111268 [19200 / 60000]\n","loss: 0.893767 [25600 / 60000]\n","loss: 1.124730 [32000 / 60000]\n","loss: 0.886591 [38400 / 60000]\n","loss: 0.992418 [44800 / 60000]\n","loss: 1.042181 [51200 / 60000]\n","loss: 1.071046 [57600 / 60000]\n","Test error: \n"," Accuracy 69.3% Avg loss 0.015531 \n","\n","epoch 14 \n"," --------------------------\n","loss: 0.934261 [    0 / 60000]\n","loss: 0.976491 [ 6400 / 60000]\n","loss: 0.848977 [12800 / 60000]\n","loss: 1.090685 [19200 / 60000]\n","loss: 0.875684 [25600 / 60000]\n","loss: 1.099916 [32000 / 60000]\n","loss: 0.866021 [38400 / 60000]\n","loss: 0.977661 [44800 / 60000]\n","loss: 1.017481 [51200 / 60000]\n","loss: 1.049900 [57600 / 60000]\n","Test error: \n"," Accuracy 70.0% Avg loss 0.015189 \n","\n","epoch 15 \n"," --------------------------\n","loss: 0.904523 [    0 / 60000]\n","loss: 0.950722 [ 6400 / 60000]\n","loss: 0.822133 [12800 / 60000]\n","loss: 1.072926 [19200 / 60000]\n","loss: 0.860451 [25600 / 60000]\n","loss: 1.078313 [32000 / 60000]\n","loss: 0.848137 [38400 / 60000]\n","loss: 0.964980 [44800 / 60000]\n","loss: 0.995902 [51200 / 60000]\n","loss: 1.031335 [57600 / 60000]\n","Test error: \n"," Accuracy 70.7% Avg loss 0.014885 \n","\n","epoch 16 \n"," --------------------------\n","loss: 0.877984 [    0 / 60000]\n","loss: 0.925975 [ 6400 / 60000]\n","loss: 0.798376 [12800 / 60000]\n","loss: 1.057306 [19200 / 60000]\n","loss: 0.846530 [25600 / 60000]\n","loss: 1.058851 [32000 / 60000]\n","loss: 0.831757 [38400 / 60000]\n","loss: 0.953439 [44800 / 60000]\n","loss: 0.976534 [51200 / 60000]\n","loss: 1.014751 [57600 / 60000]\n","Test error: \n"," Accuracy 71.5% Avg loss 0.014610 \n","\n","epoch 17 \n"," --------------------------\n","loss: 0.854117 [    0 / 60000]\n","loss: 0.903001 [ 6400 / 60000]\n","loss: 0.777065 [12800 / 60000]\n","loss: 1.043139 [19200 / 60000]\n","loss: 0.833995 [25600 / 60000]\n","loss: 1.041546 [32000 / 60000]\n","loss: 0.817143 [38400 / 60000]\n","loss: 0.943101 [44800 / 60000]\n","loss: 0.958990 [51200 / 60000]\n","loss: 0.999909 [57600 / 60000]\n","Test error: \n"," Accuracy 72.0% Avg loss 0.014359 \n","\n","epoch 18 \n"," --------------------------\n","loss: 0.832615 [    0 / 60000]\n","loss: 0.882202 [ 6400 / 60000]\n","loss: 0.757489 [12800 / 60000]\n","loss: 1.030086 [19200 / 60000]\n","loss: 0.822368 [25600 / 60000]\n","loss: 1.025562 [32000 / 60000]\n","loss: 0.803887 [38400 / 60000]\n","loss: 0.933265 [44800 / 60000]\n","loss: 0.942855 [51200 / 60000]\n","loss: 0.986287 [57600 / 60000]\n","Test error: \n"," Accuracy 72.4% Avg loss 0.014127 \n","\n","epoch 19 \n"," --------------------------\n","loss: 0.812715 [    0 / 60000]\n","loss: 0.863339 [ 6400 / 60000]\n","loss: 0.739510 [12800 / 60000]\n","loss: 1.017943 [19200 / 60000]\n","loss: 0.812134 [25600 / 60000]\n","loss: 1.010774 [32000 / 60000]\n","loss: 0.791547 [38400 / 60000]\n","loss: 0.924538 [44800 / 60000]\n","loss: 0.927898 [51200 / 60000]\n","loss: 0.973537 [57600 / 60000]\n","Test error: \n"," Accuracy 72.8% Avg loss 0.013911 \n","\n","epoch 20 \n"," --------------------------\n","loss: 0.794534 [    0 / 60000]\n","loss: 0.845976 [ 6400 / 60000]\n","loss: 0.723071 [12800 / 60000]\n","loss: 1.006614 [19200 / 60000]\n","loss: 0.803229 [25600 / 60000]\n","loss: 0.997251 [32000 / 60000]\n","loss: 0.780384 [38400 / 60000]\n","loss: 0.916593 [44800 / 60000]\n","loss: 0.914603 [51200 / 60000]\n","loss: 0.961683 [57600 / 60000]\n","Test error: \n"," Accuracy 73.2% Avg loss 0.013711 \n","\n","epoch 21 \n"," --------------------------\n","loss: 0.777754 [    0 / 60000]\n","loss: 0.829989 [ 6400 / 60000]\n","loss: 0.707834 [12800 / 60000]\n","loss: 0.995895 [19200 / 60000]\n","loss: 0.794667 [25600 / 60000]\n","loss: 0.984580 [32000 / 60000]\n","loss: 0.769873 [38400 / 60000]\n","loss: 0.909233 [44800 / 60000]\n","loss: 0.902929 [51200 / 60000]\n","loss: 0.950479 [57600 / 60000]\n","Test error: \n"," Accuracy 73.4% Avg loss 0.013522 \n","\n","epoch 22 \n"," --------------------------\n","loss: 0.762197 [    0 / 60000]\n","loss: 0.815309 [ 6400 / 60000]\n","loss: 0.693794 [12800 / 60000]\n","loss: 0.985550 [19200 / 60000]\n","loss: 0.786662 [25600 / 60000]\n","loss: 0.973166 [32000 / 60000]\n","loss: 0.760108 [38400 / 60000]\n","loss: 0.902579 [44800 / 60000]\n","loss: 0.892728 [51200 / 60000]\n","loss: 0.939841 [57600 / 60000]\n","Test error: \n"," Accuracy 73.7% Avg loss 0.013346 \n","\n","epoch 23 \n"," --------------------------\n","loss: 0.747656 [    0 / 60000]\n","loss: 0.801825 [ 6400 / 60000]\n","loss: 0.680900 [12800 / 60000]\n","loss: 0.975416 [19200 / 60000]\n","loss: 0.778532 [25600 / 60000]\n","loss: 0.962591 [32000 / 60000]\n","loss: 0.751271 [38400 / 60000]\n","loss: 0.896716 [44800 / 60000]\n","loss: 0.883572 [51200 / 60000]\n","loss: 0.929706 [57600 / 60000]\n","Test error: \n"," Accuracy 73.9% Avg loss 0.013181 \n","\n","epoch 24 \n"," --------------------------\n","loss: 0.734031 [    0 / 60000]\n","loss: 0.789481 [ 6400 / 60000]\n","loss: 0.668969 [12800 / 60000]\n","loss: 0.965516 [19200 / 60000]\n","loss: 0.770838 [25600 / 60000]\n","loss: 0.952467 [32000 / 60000]\n","loss: 0.743113 [38400 / 60000]\n","loss: 0.891527 [44800 / 60000]\n","loss: 0.875525 [51200 / 60000]\n","loss: 0.919973 [57600 / 60000]\n","Test error: \n"," Accuracy 74.0% Avg loss 0.013027 \n","\n","epoch 25 \n"," --------------------------\n","loss: 0.721266 [    0 / 60000]\n","loss: 0.778194 [ 6400 / 60000]\n","loss: 0.657803 [12800 / 60000]\n","loss: 0.955815 [19200 / 60000]\n","loss: 0.763755 [25600 / 60000]\n","loss: 0.942825 [32000 / 60000]\n","loss: 0.735649 [38400 / 60000]\n","loss: 0.886890 [44800 / 60000]\n","loss: 0.868495 [51200 / 60000]\n","loss: 0.910592 [57600 / 60000]\n","Test error: \n"," Accuracy 74.2% Avg loss 0.012880 \n","\n","epoch 26 \n"," --------------------------\n","loss: 0.709261 [    0 / 60000]\n","loss: 0.767694 [ 6400 / 60000]\n","loss: 0.647553 [12800 / 60000]\n","loss: 0.946367 [19200 / 60000]\n","loss: 0.757378 [25600 / 60000]\n","loss: 0.934103 [32000 / 60000]\n","loss: 0.728703 [38400 / 60000]\n","loss: 0.883093 [44800 / 60000]\n","loss: 0.862322 [51200 / 60000]\n","loss: 0.901415 [57600 / 60000]\n","Test error: \n"," Accuracy 74.3% Avg loss 0.012742 \n","\n","epoch 27 \n"," --------------------------\n","loss: 0.697800 [    0 / 60000]\n","loss: 0.758091 [ 6400 / 60000]\n","loss: 0.637820 [12800 / 60000]\n","loss: 0.937317 [19200 / 60000]\n","loss: 0.750716 [25600 / 60000]\n","loss: 0.926217 [32000 / 60000]\n","loss: 0.722293 [38400 / 60000]\n","loss: 0.880253 [44800 / 60000]\n","loss: 0.856660 [51200 / 60000]\n","loss: 0.892568 [57600 / 60000]\n","Test error: \n"," Accuracy 74.5% Avg loss 0.012611 \n","\n","epoch 28 \n"," --------------------------\n","loss: 0.687229 [    0 / 60000]\n","loss: 0.749290 [ 6400 / 60000]\n","loss: 0.628898 [12800 / 60000]\n","loss: 0.928633 [19200 / 60000]\n","loss: 0.744623 [25600 / 60000]\n","loss: 0.918701 [32000 / 60000]\n","loss: 0.716289 [38400 / 60000]\n","loss: 0.877200 [44800 / 60000]\n","loss: 0.851441 [51200 / 60000]\n","loss: 0.884012 [57600 / 60000]\n","Test error: \n"," Accuracy 74.6% Avg loss 0.012488 \n","\n","epoch 29 \n"," --------------------------\n","loss: 0.677428 [    0 / 60000]\n","loss: 0.741219 [ 6400 / 60000]\n","loss: 0.620524 [12800 / 60000]\n","loss: 0.920302 [19200 / 60000]\n","loss: 0.738429 [25600 / 60000]\n","loss: 0.911597 [32000 / 60000]\n","loss: 0.710705 [38400 / 60000]\n","loss: 0.874201 [44800 / 60000]\n","loss: 0.846186 [51200 / 60000]\n","loss: 0.875805 [57600 / 60000]\n","Test error: \n"," Accuracy 74.8% Avg loss 0.012373 \n","\n","epoch 30 \n"," --------------------------\n","loss: 0.667994 [    0 / 60000]\n","loss: 0.733791 [ 6400 / 60000]\n","loss: 0.612763 [12800 / 60000]\n","loss: 0.912087 [19200 / 60000]\n","loss: 0.732649 [25600 / 60000]\n","loss: 0.904782 [32000 / 60000]\n","loss: 0.705383 [38400 / 60000]\n","loss: 0.871941 [44800 / 60000]\n","loss: 0.842018 [51200 / 60000]\n","loss: 0.867832 [57600 / 60000]\n","Test error: \n"," Accuracy 74.9% Avg loss 0.012263 \n","\n","epoch 31 \n"," --------------------------\n","loss: 0.659213 [    0 / 60000]\n","loss: 0.726508 [ 6400 / 60000]\n","loss: 0.605614 [12800 / 60000]\n","loss: 0.904383 [19200 / 60000]\n","loss: 0.726991 [25600 / 60000]\n","loss: 0.898235 [32000 / 60000]\n","loss: 0.700593 [38400 / 60000]\n","loss: 0.869833 [44800 / 60000]\n","loss: 0.838095 [51200 / 60000]\n","loss: 0.860032 [57600 / 60000]\n","Test error: \n"," Accuracy 75.0% Avg loss 0.012161 \n","\n","epoch 32 \n"," --------------------------\n","loss: 0.650995 [    0 / 60000]\n","loss: 0.719536 [ 6400 / 60000]\n","loss: 0.598811 [12800 / 60000]\n","loss: 0.896736 [19200 / 60000]\n","loss: 0.721668 [25600 / 60000]\n","loss: 0.892506 [32000 / 60000]\n","loss: 0.696234 [38400 / 60000]\n","loss: 0.868008 [44800 / 60000]\n","loss: 0.834536 [51200 / 60000]\n","loss: 0.852543 [57600 / 60000]\n","Test error: \n"," Accuracy 75.2% Avg loss 0.012064 \n","\n","epoch 33 \n"," --------------------------\n","loss: 0.643345 [    0 / 60000]\n","loss: 0.712939 [ 6400 / 60000]\n","loss: 0.592747 [12800 / 60000]\n","loss: 0.889447 [19200 / 60000]\n","loss: 0.716230 [25600 / 60000]\n","loss: 0.886800 [32000 / 60000]\n","loss: 0.691488 [38400 / 60000]\n","loss: 0.866488 [44800 / 60000]\n","loss: 0.831087 [51200 / 60000]\n","loss: 0.845200 [57600 / 60000]\n","Test error: \n"," Accuracy 75.3% Avg loss 0.011973 \n","\n","epoch 34 \n"," --------------------------\n","loss: 0.635882 [    0 / 60000]\n","loss: 0.706836 [ 6400 / 60000]\n","loss: 0.587126 [12800 / 60000]\n","loss: 0.882556 [19200 / 60000]\n","loss: 0.711201 [25600 / 60000]\n","loss: 0.881256 [32000 / 60000]\n","loss: 0.685964 [38400 / 60000]\n","loss: 0.865394 [44800 / 60000]\n","loss: 0.827902 [51200 / 60000]\n","loss: 0.838142 [57600 / 60000]\n","Test error: \n"," Accuracy 75.5% Avg loss 0.011888 \n","\n","epoch 35 \n"," --------------------------\n","loss: 0.628677 [    0 / 60000]\n","loss: 0.701138 [ 6400 / 60000]\n","loss: 0.581751 [12800 / 60000]\n","loss: 0.876004 [19200 / 60000]\n","loss: 0.706137 [25600 / 60000]\n","loss: 0.875960 [32000 / 60000]\n","loss: 0.681074 [38400 / 60000]\n","loss: 0.864072 [44800 / 60000]\n","loss: 0.825272 [51200 / 60000]\n","loss: 0.831297 [57600 / 60000]\n","Test error: \n"," Accuracy 75.6% Avg loss 0.011809 \n","\n","epoch 36 \n"," --------------------------\n","loss: 0.622065 [    0 / 60000]\n","loss: 0.695778 [ 6400 / 60000]\n","loss: 0.576761 [12800 / 60000]\n","loss: 0.869644 [19200 / 60000]\n","loss: 0.701051 [25600 / 60000]\n","loss: 0.870645 [32000 / 60000]\n","loss: 0.676260 [38400 / 60000]\n","loss: 0.863182 [44800 / 60000]\n","loss: 0.823071 [51200 / 60000]\n","loss: 0.824522 [57600 / 60000]\n","Test error: \n"," Accuracy 75.6% Avg loss 0.011734 \n","\n","epoch 37 \n"," --------------------------\n","loss: 0.615781 [    0 / 60000]\n","loss: 0.690857 [ 6400 / 60000]\n","loss: 0.571980 [12800 / 60000]\n","loss: 0.863378 [19200 / 60000]\n","loss: 0.696368 [25600 / 60000]\n","loss: 0.866140 [32000 / 60000]\n","loss: 0.671749 [38400 / 60000]\n","loss: 0.862577 [44800 / 60000]\n","loss: 0.820941 [51200 / 60000]\n","loss: 0.818241 [57600 / 60000]\n","Test error: \n"," Accuracy 75.8% Avg loss 0.011665 \n","\n","epoch 38 \n"," --------------------------\n","loss: 0.609837 [    0 / 60000]\n","loss: 0.686213 [ 6400 / 60000]\n","loss: 0.567574 [12800 / 60000]\n","loss: 0.857545 [19200 / 60000]\n","loss: 0.691459 [25600 / 60000]\n","loss: 0.861869 [32000 / 60000]\n","loss: 0.667424 [38400 / 60000]\n","loss: 0.862070 [44800 / 60000]\n","loss: 0.818709 [51200 / 60000]\n","loss: 0.812199 [57600 / 60000]\n","Test error: \n"," Accuracy 75.9% Avg loss 0.011599 \n","\n","epoch 39 \n"," --------------------------\n","loss: 0.604075 [    0 / 60000]\n","loss: 0.681979 [ 6400 / 60000]\n","loss: 0.563308 [12800 / 60000]\n","loss: 0.851826 [19200 / 60000]\n","loss: 0.686780 [25600 / 60000]\n","loss: 0.857065 [32000 / 60000]\n","loss: 0.663755 [38400 / 60000]\n","loss: 0.861061 [44800 / 60000]\n","loss: 0.816303 [51200 / 60000]\n","loss: 0.806183 [57600 / 60000]\n","Test error: \n"," Accuracy 76.0% Avg loss 0.011537 \n","\n","epoch 40 \n"," --------------------------\n","loss: 0.598511 [    0 / 60000]\n","loss: 0.677903 [ 6400 / 60000]\n","loss: 0.559367 [12800 / 60000]\n","loss: 0.846153 [19200 / 60000]\n","loss: 0.682530 [25600 / 60000]\n","loss: 0.853034 [32000 / 60000]\n","loss: 0.659737 [38400 / 60000]\n","loss: 0.860354 [44800 / 60000]\n","loss: 0.813932 [51200 / 60000]\n","loss: 0.800628 [57600 / 60000]\n","Test error: \n"," Accuracy 76.1% Avg loss 0.011478 \n","\n","epoch 41 \n"," --------------------------\n","loss: 0.593327 [    0 / 60000]\n","loss: 0.674351 [ 6400 / 60000]\n","loss: 0.555683 [12800 / 60000]\n","loss: 0.840779 [19200 / 60000]\n","loss: 0.678500 [25600 / 60000]\n","loss: 0.849608 [32000 / 60000]\n","loss: 0.656094 [38400 / 60000]\n","loss: 0.859853 [44800 / 60000]\n","loss: 0.811917 [51200 / 60000]\n","loss: 0.795039 [57600 / 60000]\n","Test error: \n"," Accuracy 76.2% Avg loss 0.011423 \n","\n","epoch 42 \n"," --------------------------\n","loss: 0.588447 [    0 / 60000]\n","loss: 0.670798 [ 6400 / 60000]\n","loss: 0.552439 [12800 / 60000]\n","loss: 0.835593 [19200 / 60000]\n","loss: 0.674064 [25600 / 60000]\n","loss: 0.846034 [32000 / 60000]\n","loss: 0.652020 [38400 / 60000]\n","loss: 0.859349 [44800 / 60000]\n","loss: 0.809578 [51200 / 60000]\n","loss: 0.789932 [57600 / 60000]\n","Test error: \n"," Accuracy 76.2% Avg loss 0.011371 \n","\n","epoch 43 \n"," --------------------------\n","loss: 0.583702 [    0 / 60000]\n","loss: 0.667285 [ 6400 / 60000]\n","loss: 0.549179 [12800 / 60000]\n","loss: 0.830475 [19200 / 60000]\n","loss: 0.669379 [25600 / 60000]\n","loss: 0.842882 [32000 / 60000]\n","loss: 0.647681 [38400 / 60000]\n","loss: 0.858835 [44800 / 60000]\n","loss: 0.807648 [51200 / 60000]\n","loss: 0.785019 [57600 / 60000]\n","Test error: \n"," Accuracy 76.3% Avg loss 0.011321 \n","\n","epoch 44 \n"," --------------------------\n","loss: 0.579041 [    0 / 60000]\n","loss: 0.664176 [ 6400 / 60000]\n","loss: 0.546008 [12800 / 60000]\n","loss: 0.825712 [19200 / 60000]\n","loss: 0.665429 [25600 / 60000]\n","loss: 0.839818 [32000 / 60000]\n","loss: 0.643478 [38400 / 60000]\n","loss: 0.858482 [44800 / 60000]\n","loss: 0.805438 [51200 / 60000]\n","loss: 0.780263 [57600 / 60000]\n","Test error: \n"," Accuracy 76.4% Avg loss 0.011275 \n","\n","epoch 45 \n"," --------------------------\n","loss: 0.574659 [    0 / 60000]\n","loss: 0.661265 [ 6400 / 60000]\n","loss: 0.543108 [12800 / 60000]\n","loss: 0.821139 [19200 / 60000]\n","loss: 0.661386 [25600 / 60000]\n","loss: 0.836805 [32000 / 60000]\n","loss: 0.639392 [38400 / 60000]\n","loss: 0.857723 [44800 / 60000]\n","loss: 0.803373 [51200 / 60000]\n","loss: 0.775653 [57600 / 60000]\n","Test error: \n"," Accuracy 76.4% Avg loss 0.011231 \n","\n","epoch 46 \n"," --------------------------\n","loss: 0.570362 [    0 / 60000]\n","loss: 0.658568 [ 6400 / 60000]\n","loss: 0.540252 [12800 / 60000]\n","loss: 0.816725 [19200 / 60000]\n","loss: 0.657540 [25600 / 60000]\n","loss: 0.834548 [32000 / 60000]\n","loss: 0.635311 [38400 / 60000]\n","loss: 0.856470 [44800 / 60000]\n","loss: 0.801249 [51200 / 60000]\n","loss: 0.771483 [57600 / 60000]\n","Test error: \n"," Accuracy 76.4% Avg loss 0.011190 \n","\n","epoch 47 \n"," --------------------------\n","loss: 0.566170 [    0 / 60000]\n","loss: 0.656062 [ 6400 / 60000]\n","loss: 0.537519 [12800 / 60000]\n","loss: 0.812575 [19200 / 60000]\n","loss: 0.653733 [25600 / 60000]\n","loss: 0.832037 [32000 / 60000]\n","loss: 0.631577 [38400 / 60000]\n","loss: 0.855313 [44800 / 60000]\n","loss: 0.799212 [51200 / 60000]\n","loss: 0.767498 [57600 / 60000]\n","Test error: \n"," Accuracy 76.5% Avg loss 0.011150 \n","\n","epoch 48 \n"," --------------------------\n","loss: 0.562168 [    0 / 60000]\n","loss: 0.653623 [ 6400 / 60000]\n","loss: 0.534878 [12800 / 60000]\n","loss: 0.808907 [19200 / 60000]\n","loss: 0.649995 [25600 / 60000]\n","loss: 0.829505 [32000 / 60000]\n","loss: 0.627902 [38400 / 60000]\n","loss: 0.853443 [44800 / 60000]\n","loss: 0.797025 [51200 / 60000]\n","loss: 0.763657 [57600 / 60000]\n","Test error: \n"," Accuracy 76.5% Avg loss 0.011112 \n","\n","epoch 49 \n"," --------------------------\n","loss: 0.558308 [    0 / 60000]\n","loss: 0.651694 [ 6400 / 60000]\n","loss: 0.532293 [12800 / 60000]\n","loss: 0.805056 [19200 / 60000]\n","loss: 0.646334 [25600 / 60000]\n","loss: 0.826854 [32000 / 60000]\n","loss: 0.624712 [38400 / 60000]\n","loss: 0.851383 [44800 / 60000]\n","loss: 0.794467 [51200 / 60000]\n","loss: 0.760064 [57600 / 60000]\n","Test error: \n"," Accuracy 76.6% Avg loss 0.011075 \n","\n","epoch 50 \n"," --------------------------\n","loss: 0.554566 [    0 / 60000]\n","loss: 0.649510 [ 6400 / 60000]\n","loss: 0.529884 [12800 / 60000]\n","loss: 0.801450 [19200 / 60000]\n","loss: 0.642671 [25600 / 60000]\n","loss: 0.824490 [32000 / 60000]\n","loss: 0.621242 [38400 / 60000]\n","loss: 0.849432 [44800 / 60000]\n","loss: 0.792430 [51200 / 60000]\n","loss: 0.756684 [57600 / 60000]\n","Test error: \n"," Accuracy 76.6% Avg loss 0.011041 \n","\n","epoch 51 \n"," --------------------------\n","loss: 0.550934 [    0 / 60000]\n","loss: 0.647409 [ 6400 / 60000]\n","loss: 0.527524 [12800 / 60000]\n","loss: 0.798020 [19200 / 60000]\n","loss: 0.638987 [25600 / 60000]\n","loss: 0.822288 [32000 / 60000]\n","loss: 0.617834 [38400 / 60000]\n","loss: 0.847373 [44800 / 60000]\n","loss: 0.790382 [51200 / 60000]\n","loss: 0.753432 [57600 / 60000]\n","Test error: \n"," Accuracy 76.8% Avg loss 0.011007 \n","\n","epoch 52 \n"," --------------------------\n","loss: 0.547325 [    0 / 60000]\n","loss: 0.645510 [ 6400 / 60000]\n","loss: 0.525278 [12800 / 60000]\n","loss: 0.794632 [19200 / 60000]\n","loss: 0.635387 [25600 / 60000]\n","loss: 0.820669 [32000 / 60000]\n","loss: 0.614443 [38400 / 60000]\n","loss: 0.845242 [44800 / 60000]\n","loss: 0.788435 [51200 / 60000]\n","loss: 0.750457 [57600 / 60000]\n","Test error: \n"," Accuracy 76.8% Avg loss 0.010975 \n","\n","epoch 53 \n"," --------------------------\n","loss: 0.543846 [    0 / 60000]\n","loss: 0.643749 [ 6400 / 60000]\n","loss: 0.523149 [12800 / 60000]\n","loss: 0.791437 [19200 / 60000]\n","loss: 0.631988 [25600 / 60000]\n","loss: 0.819074 [32000 / 60000]\n","loss: 0.610905 [38400 / 60000]\n","loss: 0.842655 [44800 / 60000]\n","loss: 0.786279 [51200 / 60000]\n","loss: 0.747583 [57600 / 60000]\n","Test error: \n"," Accuracy 76.9% Avg loss 0.010944 \n","\n","epoch 54 \n"," --------------------------\n","loss: 0.540575 [    0 / 60000]\n","loss: 0.641925 [ 6400 / 60000]\n","loss: 0.521108 [12800 / 60000]\n","loss: 0.788420 [19200 / 60000]\n","loss: 0.628564 [25600 / 60000]\n","loss: 0.817174 [32000 / 60000]\n","loss: 0.607513 [38400 / 60000]\n","loss: 0.840680 [44800 / 60000]\n","loss: 0.783975 [51200 / 60000]\n","loss: 0.744851 [57600 / 60000]\n","Test error: \n"," Accuracy 77.0% Avg loss 0.010914 \n","\n","epoch 55 \n"," --------------------------\n","loss: 0.537327 [    0 / 60000]\n","loss: 0.640244 [ 6400 / 60000]\n","loss: 0.519157 [12800 / 60000]\n","loss: 0.785463 [19200 / 60000]\n","loss: 0.625215 [25600 / 60000]\n","loss: 0.815376 [32000 / 60000]\n","loss: 0.603924 [38400 / 60000]\n","loss: 0.838826 [44800 / 60000]\n","loss: 0.781792 [51200 / 60000]\n","loss: 0.742124 [57600 / 60000]\n","Test error: \n"," Accuracy 77.1% Avg loss 0.010886 \n","\n","epoch 56 \n"," --------------------------\n","loss: 0.534146 [    0 / 60000]\n","loss: 0.638562 [ 6400 / 60000]\n","loss: 0.517349 [12800 / 60000]\n","loss: 0.782692 [19200 / 60000]\n","loss: 0.621825 [25600 / 60000]\n","loss: 0.813661 [32000 / 60000]\n","loss: 0.600586 [38400 / 60000]\n","loss: 0.836875 [44800 / 60000]\n","loss: 0.779754 [51200 / 60000]\n","loss: 0.739736 [57600 / 60000]\n","Test error: \n"," Accuracy 77.1% Avg loss 0.010858 \n","\n","epoch 57 \n"," --------------------------\n","loss: 0.531098 [    0 / 60000]\n","loss: 0.636791 [ 6400 / 60000]\n","loss: 0.515428 [12800 / 60000]\n","loss: 0.780151 [19200 / 60000]\n","loss: 0.618614 [25600 / 60000]\n","loss: 0.811876 [32000 / 60000]\n","loss: 0.596977 [38400 / 60000]\n","loss: 0.834874 [44800 / 60000]\n","loss: 0.777264 [51200 / 60000]\n","loss: 0.737423 [57600 / 60000]\n","Test error: \n"," Accuracy 77.1% Avg loss 0.010832 \n","\n","epoch 58 \n"," --------------------------\n","loss: 0.528042 [    0 / 60000]\n","loss: 0.635184 [ 6400 / 60000]\n","loss: 0.513574 [12800 / 60000]\n","loss: 0.777670 [19200 / 60000]\n","loss: 0.615469 [25600 / 60000]\n","loss: 0.810216 [32000 / 60000]\n","loss: 0.593631 [38400 / 60000]\n","loss: 0.832965 [44800 / 60000]\n","loss: 0.775216 [51200 / 60000]\n","loss: 0.734801 [57600 / 60000]\n","Test error: \n"," Accuracy 77.1% Avg loss 0.010806 \n","\n","epoch 59 \n"," --------------------------\n","loss: 0.525119 [    0 / 60000]\n","loss: 0.633651 [ 6400 / 60000]\n","loss: 0.511609 [12800 / 60000]\n","loss: 0.775240 [19200 / 60000]\n","loss: 0.612530 [25600 / 60000]\n","loss: 0.808701 [32000 / 60000]\n","loss: 0.590523 [38400 / 60000]\n","loss: 0.831017 [44800 / 60000]\n","loss: 0.773194 [51200 / 60000]\n","loss: 0.732261 [57600 / 60000]\n","Test error: \n"," Accuracy 77.1% Avg loss 0.010781 \n","\n","epoch 60 \n"," --------------------------\n","loss: 0.522330 [    0 / 60000]\n","loss: 0.632061 [ 6400 / 60000]\n","loss: 0.509867 [12800 / 60000]\n","loss: 0.773010 [19200 / 60000]\n","loss: 0.609564 [25600 / 60000]\n","loss: 0.806859 [32000 / 60000]\n","loss: 0.587426 [38400 / 60000]\n","loss: 0.829006 [44800 / 60000]\n","loss: 0.771151 [51200 / 60000]\n","loss: 0.730179 [57600 / 60000]\n","Test error: \n"," Accuracy 77.2% Avg loss 0.010757 \n","\n","epoch 61 \n"," --------------------------\n","loss: 0.519591 [    0 / 60000]\n","loss: 0.630535 [ 6400 / 60000]\n","loss: 0.508310 [12800 / 60000]\n","loss: 0.770902 [19200 / 60000]\n","loss: 0.606654 [25600 / 60000]\n","loss: 0.806104 [32000 / 60000]\n","loss: 0.584435 [38400 / 60000]\n","loss: 0.827037 [44800 / 60000]\n","loss: 0.768842 [51200 / 60000]\n","loss: 0.728137 [57600 / 60000]\n","Test error: \n"," Accuracy 77.2% Avg loss 0.010734 \n","\n","epoch 62 \n"," --------------------------\n","loss: 0.516826 [    0 / 60000]\n","loss: 0.628989 [ 6400 / 60000]\n","loss: 0.506646 [12800 / 60000]\n","loss: 0.769323 [19200 / 60000]\n","loss: 0.603681 [25600 / 60000]\n","loss: 0.804649 [32000 / 60000]\n","loss: 0.581465 [38400 / 60000]\n","loss: 0.825023 [44800 / 60000]\n","loss: 0.766987 [51200 / 60000]\n","loss: 0.726310 [57600 / 60000]\n","Test error: \n"," Accuracy 77.3% Avg loss 0.010712 \n","\n","epoch 63 \n"," --------------------------\n","loss: 0.514155 [    0 / 60000]\n","loss: 0.627426 [ 6400 / 60000]\n","loss: 0.505045 [12800 / 60000]\n","loss: 0.767366 [19200 / 60000]\n","loss: 0.600260 [25600 / 60000]\n","loss: 0.803133 [32000 / 60000]\n","loss: 0.578643 [38400 / 60000]\n","loss: 0.822695 [44800 / 60000]\n","loss: 0.765248 [51200 / 60000]\n","loss: 0.724536 [57600 / 60000]\n","Test error: \n"," Accuracy 77.3% Avg loss 0.010690 \n","\n","epoch 64 \n"," --------------------------\n","loss: 0.511575 [    0 / 60000]\n","loss: 0.625829 [ 6400 / 60000]\n","loss: 0.503448 [12800 / 60000]\n","loss: 0.765526 [19200 / 60000]\n","loss: 0.597629 [25600 / 60000]\n","loss: 0.801997 [32000 / 60000]\n","loss: 0.575892 [38400 / 60000]\n","loss: 0.820323 [44800 / 60000]\n","loss: 0.763114 [51200 / 60000]\n","loss: 0.722984 [57600 / 60000]\n","Test error: \n"," Accuracy 77.3% Avg loss 0.010668 \n","\n","epoch 65 \n"," --------------------------\n","loss: 0.509122 [    0 / 60000]\n","loss: 0.624328 [ 6400 / 60000]\n","loss: 0.501922 [12800 / 60000]\n","loss: 0.763621 [19200 / 60000]\n","loss: 0.594875 [25600 / 60000]\n","loss: 0.800701 [32000 / 60000]\n","loss: 0.573210 [38400 / 60000]\n","loss: 0.818403 [44800 / 60000]\n","loss: 0.761196 [51200 / 60000]\n","loss: 0.721236 [57600 / 60000]\n","Test error: \n"," Accuracy 77.3% Avg loss 0.010648 \n","\n","epoch 66 \n"," --------------------------\n","loss: 0.506813 [    0 / 60000]\n","loss: 0.622859 [ 6400 / 60000]\n","loss: 0.500469 [12800 / 60000]\n","loss: 0.761867 [19200 / 60000]\n","loss: 0.592268 [25600 / 60000]\n","loss: 0.799660 [32000 / 60000]\n","loss: 0.570728 [38400 / 60000]\n","loss: 0.816515 [44800 / 60000]\n","loss: 0.759237 [51200 / 60000]\n","loss: 0.719615 [57600 / 60000]\n","Test error: \n"," Accuracy 77.3% Avg loss 0.010627 \n","\n","epoch 67 \n"," --------------------------\n","loss: 0.504393 [    0 / 60000]\n","loss: 0.621471 [ 6400 / 60000]\n","loss: 0.499054 [12800 / 60000]\n","loss: 0.760110 [19200 / 60000]\n","loss: 0.589863 [25600 / 60000]\n","loss: 0.798470 [32000 / 60000]\n","loss: 0.568184 [38400 / 60000]\n","loss: 0.814507 [44800 / 60000]\n","loss: 0.757750 [51200 / 60000]\n","loss: 0.718305 [57600 / 60000]\n","Test error: \n"," Accuracy 77.3% Avg loss 0.010608 \n","\n","epoch 68 \n"," --------------------------\n","loss: 0.502150 [    0 / 60000]\n","loss: 0.620026 [ 6400 / 60000]\n","loss: 0.497805 [12800 / 60000]\n","loss: 0.758629 [19200 / 60000]\n","loss: 0.587351 [25600 / 60000]\n","loss: 0.797362 [32000 / 60000]\n","loss: 0.565606 [38400 / 60000]\n","loss: 0.812220 [44800 / 60000]\n","loss: 0.756050 [51200 / 60000]\n","loss: 0.716920 [57600 / 60000]\n","Test error: \n"," Accuracy 77.4% Avg loss 0.010588 \n","\n","epoch 69 \n"," --------------------------\n","loss: 0.499926 [    0 / 60000]\n","loss: 0.618639 [ 6400 / 60000]\n","loss: 0.496614 [12800 / 60000]\n","loss: 0.757035 [19200 / 60000]\n","loss: 0.585008 [25600 / 60000]\n","loss: 0.796298 [32000 / 60000]\n","loss: 0.563151 [38400 / 60000]\n","loss: 0.810351 [44800 / 60000]\n","loss: 0.754312 [51200 / 60000]\n","loss: 0.715728 [57600 / 60000]\n","Test error: \n"," Accuracy 77.4% Avg loss 0.010569 \n","\n","epoch 70 \n"," --------------------------\n","loss: 0.497796 [    0 / 60000]\n","loss: 0.617231 [ 6400 / 60000]\n","loss: 0.495383 [12800 / 60000]\n","loss: 0.755502 [19200 / 60000]\n","loss: 0.582683 [25600 / 60000]\n","loss: 0.795092 [32000 / 60000]\n","loss: 0.560833 [38400 / 60000]\n","loss: 0.808336 [44800 / 60000]\n","loss: 0.752664 [51200 / 60000]\n","loss: 0.714378 [57600 / 60000]\n","Test error: \n"," Accuracy 77.5% Avg loss 0.010551 \n","\n","epoch 71 \n"," --------------------------\n","loss: 0.495659 [    0 / 60000]\n","loss: 0.615742 [ 6400 / 60000]\n","loss: 0.494212 [12800 / 60000]\n","loss: 0.753988 [19200 / 60000]\n","loss: 0.580537 [25600 / 60000]\n","loss: 0.794125 [32000 / 60000]\n","loss: 0.558364 [38400 / 60000]\n","loss: 0.806510 [44800 / 60000]\n","loss: 0.750911 [51200 / 60000]\n","loss: 0.713334 [57600 / 60000]\n","Test error: \n"," Accuracy 77.5% Avg loss 0.010533 \n","\n","epoch 72 \n"," --------------------------\n","loss: 0.493613 [    0 / 60000]\n","loss: 0.614335 [ 6400 / 60000]\n","loss: 0.493022 [12800 / 60000]\n","loss: 0.752526 [19200 / 60000]\n","loss: 0.578309 [25600 / 60000]\n","loss: 0.793163 [32000 / 60000]\n","loss: 0.556211 [38400 / 60000]\n","loss: 0.804651 [44800 / 60000]\n","loss: 0.749201 [51200 / 60000]\n","loss: 0.712214 [57600 / 60000]\n","Test error: \n"," Accuracy 77.5% Avg loss 0.010515 \n","\n","epoch 73 \n"," --------------------------\n","loss: 0.491604 [    0 / 60000]\n","loss: 0.612820 [ 6400 / 60000]\n","loss: 0.491810 [12800 / 60000]\n","loss: 0.751133 [19200 / 60000]\n","loss: 0.576010 [25600 / 60000]\n","loss: 0.792203 [32000 / 60000]\n","loss: 0.553962 [38400 / 60000]\n","loss: 0.802806 [44800 / 60000]\n","loss: 0.747559 [51200 / 60000]\n","loss: 0.711228 [57600 / 60000]\n","Test error: \n"," Accuracy 77.6% Avg loss 0.010498 \n","\n","epoch 74 \n"," --------------------------\n","loss: 0.489628 [    0 / 60000]\n","loss: 0.611357 [ 6400 / 60000]\n","loss: 0.490599 [12800 / 60000]\n","loss: 0.749740 [19200 / 60000]\n","loss: 0.573838 [25600 / 60000]\n","loss: 0.791267 [32000 / 60000]\n","loss: 0.551888 [38400 / 60000]\n","loss: 0.801005 [44800 / 60000]\n","loss: 0.745770 [51200 / 60000]\n","loss: 0.710301 [57600 / 60000]\n","Test error: \n"," Accuracy 77.6% Avg loss 0.010481 \n","\n","epoch 75 \n"," --------------------------\n","loss: 0.487814 [    0 / 60000]\n","loss: 0.609933 [ 6400 / 60000]\n","loss: 0.489522 [12800 / 60000]\n","loss: 0.748393 [19200 / 60000]\n","loss: 0.571610 [25600 / 60000]\n","loss: 0.790268 [32000 / 60000]\n","loss: 0.549803 [38400 / 60000]\n","loss: 0.799312 [44800 / 60000]\n","loss: 0.744187 [51200 / 60000]\n","loss: 0.709823 [57600 / 60000]\n","Test error: \n"," Accuracy 77.6% Avg loss 0.010464 \n","\n","epoch 76 \n"," --------------------------\n","loss: 0.486084 [    0 / 60000]\n","loss: 0.608541 [ 6400 / 60000]\n","loss: 0.488476 [12800 / 60000]\n","loss: 0.747113 [19200 / 60000]\n","loss: 0.569153 [25600 / 60000]\n","loss: 0.789567 [32000 / 60000]\n","loss: 0.547645 [38400 / 60000]\n","loss: 0.797490 [44800 / 60000]\n","loss: 0.742504 [51200 / 60000]\n","loss: 0.708736 [57600 / 60000]\n","Test error: \n"," Accuracy 77.7% Avg loss 0.010447 \n","\n","epoch 77 \n"," --------------------------\n","loss: 0.484292 [    0 / 60000]\n","loss: 0.607176 [ 6400 / 60000]\n","loss: 0.487314 [12800 / 60000]\n","loss: 0.745857 [19200 / 60000]\n","loss: 0.566895 [25600 / 60000]\n","loss: 0.788590 [32000 / 60000]\n","loss: 0.545597 [38400 / 60000]\n","loss: 0.795651 [44800 / 60000]\n","loss: 0.740772 [51200 / 60000]\n","loss: 0.708015 [57600 / 60000]\n","Test error: \n"," Accuracy 77.7% Avg loss 0.010431 \n","\n","epoch 78 \n"," --------------------------\n","loss: 0.482691 [    0 / 60000]\n","loss: 0.605884 [ 6400 / 60000]\n","loss: 0.486255 [12800 / 60000]\n","loss: 0.744673 [19200 / 60000]\n","loss: 0.564750 [25600 / 60000]\n","loss: 0.787655 [32000 / 60000]\n","loss: 0.543491 [38400 / 60000]\n","loss: 0.793848 [44800 / 60000]\n","loss: 0.739263 [51200 / 60000]\n","loss: 0.707307 [57600 / 60000]\n","Test error: \n"," Accuracy 77.7% Avg loss 0.010415 \n","\n","epoch 79 \n"," --------------------------\n","loss: 0.480976 [    0 / 60000]\n","loss: 0.604470 [ 6400 / 60000]\n","loss: 0.485243 [12800 / 60000]\n","loss: 0.743444 [19200 / 60000]\n","loss: 0.562626 [25600 / 60000]\n","loss: 0.786739 [32000 / 60000]\n","loss: 0.541320 [38400 / 60000]\n","loss: 0.792101 [44800 / 60000]\n","loss: 0.737762 [51200 / 60000]\n","loss: 0.706590 [57600 / 60000]\n","Test error: \n"," Accuracy 77.8% Avg loss 0.010399 \n","\n","epoch 80 \n"," --------------------------\n","loss: 0.479372 [    0 / 60000]\n","loss: 0.603134 [ 6400 / 60000]\n","loss: 0.484248 [12800 / 60000]\n","loss: 0.742290 [19200 / 60000]\n","loss: 0.560462 [25600 / 60000]\n","loss: 0.785181 [32000 / 60000]\n","loss: 0.539298 [38400 / 60000]\n","loss: 0.790296 [44800 / 60000]\n","loss: 0.736180 [51200 / 60000]\n","loss: 0.705867 [57600 / 60000]\n","Test error: \n"," Accuracy 77.8% Avg loss 0.010383 \n","\n","epoch 81 \n"," --------------------------\n","loss: 0.477744 [    0 / 60000]\n","loss: 0.601931 [ 6400 / 60000]\n","loss: 0.483201 [12800 / 60000]\n","loss: 0.741198 [19200 / 60000]\n","loss: 0.558307 [25600 / 60000]\n","loss: 0.784069 [32000 / 60000]\n","loss: 0.537469 [38400 / 60000]\n","loss: 0.788582 [44800 / 60000]\n","loss: 0.734302 [51200 / 60000]\n","loss: 0.705160 [57600 / 60000]\n","Test error: \n"," Accuracy 77.8% Avg loss 0.010368 \n","\n","epoch 82 \n"," --------------------------\n","loss: 0.476126 [    0 / 60000]\n","loss: 0.600702 [ 6400 / 60000]\n","loss: 0.482118 [12800 / 60000]\n","loss: 0.739996 [19200 / 60000]\n","loss: 0.555657 [25600 / 60000]\n","loss: 0.783079 [32000 / 60000]\n","loss: 0.535538 [38400 / 60000]\n","loss: 0.786745 [44800 / 60000]\n","loss: 0.732865 [51200 / 60000]\n","loss: 0.704479 [57600 / 60000]\n","Test error: \n"," Accuracy 77.8% Avg loss 0.010352 \n","\n","epoch 83 \n"," --------------------------\n","loss: 0.474550 [    0 / 60000]\n","loss: 0.599468 [ 6400 / 60000]\n","loss: 0.481110 [12800 / 60000]\n","loss: 0.738854 [19200 / 60000]\n","loss: 0.553512 [25600 / 60000]\n","loss: 0.782063 [32000 / 60000]\n","loss: 0.533850 [38400 / 60000]\n","loss: 0.785139 [44800 / 60000]\n","loss: 0.731466 [51200 / 60000]\n","loss: 0.703847 [57600 / 60000]\n","Test error: \n"," Accuracy 77.9% Avg loss 0.010337 \n","\n","epoch 84 \n"," --------------------------\n","loss: 0.472977 [    0 / 60000]\n","loss: 0.598274 [ 6400 / 60000]\n","loss: 0.480151 [12800 / 60000]\n","loss: 0.737855 [19200 / 60000]\n","loss: 0.551446 [25600 / 60000]\n","loss: 0.781057 [32000 / 60000]\n","loss: 0.532121 [38400 / 60000]\n","loss: 0.783566 [44800 / 60000]\n","loss: 0.730032 [51200 / 60000]\n","loss: 0.703004 [57600 / 60000]\n","Test error: \n"," Accuracy 77.9% Avg loss 0.010322 \n","\n","epoch 85 \n"," --------------------------\n","loss: 0.471464 [    0 / 60000]\n","loss: 0.597145 [ 6400 / 60000]\n","loss: 0.479164 [12800 / 60000]\n","loss: 0.736838 [19200 / 60000]\n","loss: 0.549398 [25600 / 60000]\n","loss: 0.779970 [32000 / 60000]\n","loss: 0.530447 [38400 / 60000]\n","loss: 0.782074 [44800 / 60000]\n","loss: 0.728669 [51200 / 60000]\n","loss: 0.702428 [57600 / 60000]\n","Test error: \n"," Accuracy 77.9% Avg loss 0.010308 \n","\n","epoch 86 \n"," --------------------------\n","loss: 0.470018 [    0 / 60000]\n","loss: 0.595945 [ 6400 / 60000]\n","loss: 0.478169 [12800 / 60000]\n","loss: 0.735759 [19200 / 60000]\n","loss: 0.547357 [25600 / 60000]\n","loss: 0.778773 [32000 / 60000]\n","loss: 0.528873 [38400 / 60000]\n","loss: 0.780584 [44800 / 60000]\n","loss: 0.727099 [51200 / 60000]\n","loss: 0.701869 [57600 / 60000]\n","Test error: \n"," Accuracy 77.9% Avg loss 0.010293 \n","\n","epoch 87 \n"," --------------------------\n","loss: 0.468558 [    0 / 60000]\n","loss: 0.594582 [ 6400 / 60000]\n","loss: 0.477179 [12800 / 60000]\n","loss: 0.734807 [19200 / 60000]\n","loss: 0.545349 [25600 / 60000]\n","loss: 0.777858 [32000 / 60000]\n","loss: 0.527278 [38400 / 60000]\n","loss: 0.778988 [44800 / 60000]\n","loss: 0.725653 [51200 / 60000]\n","loss: 0.701176 [57600 / 60000]\n","Test error: \n"," Accuracy 78.0% Avg loss 0.010279 \n","\n","epoch 88 \n"," --------------------------\n","loss: 0.467175 [    0 / 60000]\n","loss: 0.593275 [ 6400 / 60000]\n","loss: 0.476403 [12800 / 60000]\n","loss: 0.734043 [19200 / 60000]\n","loss: 0.543325 [25600 / 60000]\n","loss: 0.777194 [32000 / 60000]\n","loss: 0.525621 [38400 / 60000]\n","loss: 0.777591 [44800 / 60000]\n","loss: 0.724244 [51200 / 60000]\n","loss: 0.700817 [57600 / 60000]\n","Test error: \n"," Accuracy 78.0% Avg loss 0.010265 \n","\n","epoch 89 \n"," --------------------------\n","loss: 0.465847 [    0 / 60000]\n","loss: 0.591973 [ 6400 / 60000]\n","loss: 0.475672 [12800 / 60000]\n","loss: 0.733084 [19200 / 60000]\n","loss: 0.541365 [25600 / 60000]\n","loss: 0.776271 [32000 / 60000]\n","loss: 0.523985 [38400 / 60000]\n","loss: 0.776265 [44800 / 60000]\n","loss: 0.722602 [51200 / 60000]\n","loss: 0.700291 [57600 / 60000]\n","Test error: \n"," Accuracy 78.0% Avg loss 0.010252 \n","\n","epoch 90 \n"," --------------------------\n","loss: 0.464541 [    0 / 60000]\n","loss: 0.590548 [ 6400 / 60000]\n","loss: 0.474801 [12800 / 60000]\n","loss: 0.732039 [19200 / 60000]\n","loss: 0.539464 [25600 / 60000]\n","loss: 0.775437 [32000 / 60000]\n","loss: 0.522567 [38400 / 60000]\n","loss: 0.774793 [44800 / 60000]\n","loss: 0.721412 [51200 / 60000]\n","loss: 0.699690 [57600 / 60000]\n","Test error: \n"," Accuracy 78.0% Avg loss 0.010238 \n","\n","epoch 91 \n"," --------------------------\n","loss: 0.463225 [    0 / 60000]\n","loss: 0.589267 [ 6400 / 60000]\n","loss: 0.474036 [12800 / 60000]\n","loss: 0.731026 [19200 / 60000]\n","loss: 0.537614 [25600 / 60000]\n","loss: 0.774331 [32000 / 60000]\n","loss: 0.521115 [38400 / 60000]\n","loss: 0.773156 [44800 / 60000]\n","loss: 0.720179 [51200 / 60000]\n","loss: 0.699108 [57600 / 60000]\n","Test error: \n"," Accuracy 78.1% Avg loss 0.010225 \n","\n","epoch 92 \n"," --------------------------\n","loss: 0.461971 [    0 / 60000]\n","loss: 0.588023 [ 6400 / 60000]\n","loss: 0.473115 [12800 / 60000]\n","loss: 0.730000 [19200 / 60000]\n","loss: 0.535255 [25600 / 60000]\n","loss: 0.773132 [32000 / 60000]\n","loss: 0.519798 [38400 / 60000]\n","loss: 0.771688 [44800 / 60000]\n","loss: 0.719018 [51200 / 60000]\n","loss: 0.698477 [57600 / 60000]\n","Test error: \n"," Accuracy 78.2% Avg loss 0.010212 \n","\n","epoch 93 \n"," --------------------------\n","loss: 0.460728 [    0 / 60000]\n","loss: 0.586803 [ 6400 / 60000]\n","loss: 0.472198 [12800 / 60000]\n","loss: 0.729010 [19200 / 60000]\n","loss: 0.533461 [25600 / 60000]\n","loss: 0.772127 [32000 / 60000]\n","loss: 0.518297 [38400 / 60000]\n","loss: 0.770303 [44800 / 60000]\n","loss: 0.717631 [51200 / 60000]\n","loss: 0.697950 [57600 / 60000]\n","Test error: \n"," Accuracy 78.2% Avg loss 0.010199 \n","\n","epoch 94 \n"," --------------------------\n","loss: 0.459503 [    0 / 60000]\n","loss: 0.585612 [ 6400 / 60000]\n","loss: 0.471325 [12800 / 60000]\n","loss: 0.728015 [19200 / 60000]\n","loss: 0.531723 [25600 / 60000]\n","loss: 0.771203 [32000 / 60000]\n","loss: 0.516962 [38400 / 60000]\n","loss: 0.768859 [44800 / 60000]\n","loss: 0.716373 [51200 / 60000]\n","loss: 0.697470 [57600 / 60000]\n","Test error: \n"," Accuracy 78.2% Avg loss 0.010186 \n","\n","epoch 95 \n"," --------------------------\n","loss: 0.458447 [    0 / 60000]\n","loss: 0.584436 [ 6400 / 60000]\n","loss: 0.470469 [12800 / 60000]\n","loss: 0.727006 [19200 / 60000]\n","loss: 0.529987 [25600 / 60000]\n","loss: 0.770311 [32000 / 60000]\n","loss: 0.515689 [38400 / 60000]\n","loss: 0.767416 [44800 / 60000]\n","loss: 0.715042 [51200 / 60000]\n","loss: 0.696915 [57600 / 60000]\n","Test error: \n"," Accuracy 78.3% Avg loss 0.010173 \n","\n","epoch 96 \n"," --------------------------\n","loss: 0.457275 [    0 / 60000]\n","loss: 0.583169 [ 6400 / 60000]\n","loss: 0.469603 [12800 / 60000]\n","loss: 0.726005 [19200 / 60000]\n","loss: 0.529213 [25600 / 60000]\n","loss: 0.768944 [32000 / 60000]\n","loss: 0.514323 [38400 / 60000]\n","loss: 0.766095 [44800 / 60000]\n","loss: 0.713777 [51200 / 60000]\n","loss: 0.696379 [57600 / 60000]\n","Test error: \n"," Accuracy 78.3% Avg loss 0.010161 \n","\n","epoch 97 \n"," --------------------------\n","loss: 0.456167 [    0 / 60000]\n","loss: 0.581854 [ 6400 / 60000]\n","loss: 0.468760 [12800 / 60000]\n","loss: 0.724997 [19200 / 60000]\n","loss: 0.527685 [25600 / 60000]\n","loss: 0.767825 [32000 / 60000]\n","loss: 0.513069 [38400 / 60000]\n","loss: 0.764611 [44800 / 60000]\n","loss: 0.712475 [51200 / 60000]\n","loss: 0.695817 [57600 / 60000]\n","Test error: \n"," Accuracy 78.2% Avg loss 0.010149 \n","\n","epoch 98 \n"," --------------------------\n","loss: 0.455079 [    0 / 60000]\n","loss: 0.580622 [ 6400 / 60000]\n","loss: 0.467908 [12800 / 60000]\n","loss: 0.724034 [19200 / 60000]\n","loss: 0.526175 [25600 / 60000]\n","loss: 0.766897 [32000 / 60000]\n","loss: 0.512097 [38400 / 60000]\n","loss: 0.762831 [44800 / 60000]\n","loss: 0.711154 [51200 / 60000]\n","loss: 0.695224 [57600 / 60000]\n","Test error: \n"," Accuracy 78.3% Avg loss 0.010137 \n","\n","epoch 99 \n"," --------------------------\n","loss: 0.454049 [    0 / 60000]\n","loss: 0.579471 [ 6400 / 60000]\n","loss: 0.467101 [12800 / 60000]\n","loss: 0.723074 [19200 / 60000]\n","loss: 0.524455 [25600 / 60000]\n","loss: 0.766139 [32000 / 60000]\n","loss: 0.510896 [38400 / 60000]\n","loss: 0.761403 [44800 / 60000]\n","loss: 0.709813 [51200 / 60000]\n","loss: 0.694554 [57600 / 60000]\n","Test error: \n"," Accuracy 78.3% Avg loss 0.010125 \n","\n","epoch 100 \n"," --------------------------\n","loss: 0.453018 [    0 / 60000]\n","loss: 0.578272 [ 6400 / 60000]\n","loss: 0.466284 [12800 / 60000]\n","loss: 0.722061 [19200 / 60000]\n","loss: 0.522931 [25600 / 60000]\n","loss: 0.765584 [32000 / 60000]\n","loss: 0.509586 [38400 / 60000]\n","loss: 0.760305 [44800 / 60000]\n","loss: 0.708495 [51200 / 60000]\n","loss: 0.693926 [57600 / 60000]\n","Test error: \n"," Accuracy 78.3% Avg loss 0.010113 \n","\n","Done!\n"]}],"source":["%matplotlib inline\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n","    )\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download = True,\n","    transform = ToTensor()\n","    )\n","\n","print(training_data)\n","print(test_data)\n","\n","train_dataloader = DataLoader(dataset=training_data, batch_size=64)\n","test_dataloader = DataLoader(dataset=test_data, batch_size=64)\n","\n","print(train_dataloader)\n","print(test_dataloader)\n","\n","class NeuralNetwork(nn.Module):\n","  def __init__(self):\n","    super(NeuralNetwork, self).__init__()\n","    self.flatten = nn.Flatten()\n","    self.liner_relu_stack = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 10),\n","        nn.ReLU()\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.liner_relu_stack(x)\n","    return logits\n","\n","model = NeuralNetwork()\n","\n","print(model)\n","\n","learing_rate = 1e-3\n","batch_size = 64\n","epochs = 100\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimazer = torch.optim.SGD(model.parameters(), lr=learing_rate)\n","\n","def train_loop(dataloader, model, loss_fn, optimazer):\n","  size = len(dataloader.dataset)\n","  for batch, (X, y) in enumerate(dataloader):\n","    pred = model(X)\n","    loss = loss_fn(pred, y)\n","\n","    optimazer.zero_grad()\n","    loss.backward()\n","    optimazer.step()\n","    if batch % 100 == 0:\n","      loss, current = loss.item(), batch * len(X)\n","\n","      print(f\"loss: {loss:>7f} [{current:>5d} / {size:>5d}]\")\n","\n","def test_loop(dataloader, model, loss_fn):\n","  size = len(dataloader.dataset)\n","  test_loss, correct = 0, 0\n","\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      pred = model(X)\n","      test_loss += loss_fn(pred, y).item()\n","      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","  test_loss /= size\n","  correct /= size\n","\n","  print(f\"Test error: \\n Accuracy {100*correct:>0.1f}% Avg loss {test_loss:>8f} \\n\")\n","\n","\n","torch.manual_seed(42)\n","\n","for i in range(epochs):\n","  print(f\"epoch {i+1} \\n --------------------------\")\n","  train_loop(dataloader = train_dataloader, model = model, loss_fn = loss_fn, optimazer = optimazer)\n","  test_loop(dataloader = test_dataloader, model = model, loss_fn = loss_fn)\n","print(\"Done!\")\n"]}]}